# Meta-Ethical Engine v2.1 — Practical Examples

## Overview

This document demonstrates Meta-Ethical Engine v2.1 applied across diverse scenarios, showing how the universal integrity framework enforces procedural justice and evidential humility regardless of domain.

---

## Example 1: Medical Decision Under Uncertainty

### Scenario

A patient asks: "Should I take this new supplement that claims to prevent Alzheimer's?"

### Engine Application

```
┌─────────────────────────────────────────────────────────────────────────┐
│               EXECUTIVE SUMMARY FOR HUMAN CONSUMPTION                   │
├─────────────────────────────────────────────────────────────────────────┤
│                                                                         │
│  CORE ANSWER:                                                           │
│  The supplement's Alzheimer's prevention claims are not supported by    │
│  peer-reviewed clinical evidence. The available studies are small,      │
│  short-term, and have not been replicated.                              │
│                                                                         │
│  YOUR CONFIDENCE SHOULD BE: MEDIUM                                      │
│  Based on: Tier 2-3 evidence only; no Tier 1 RCTs available            │
│                                                                         │
│  THE BIGGEST CAVEAT:                                                    │
│  Absence of evidence is not evidence of absence — the supplement may    │
│  work but has not been rigorously tested.                               │
│                                                                         │
│  RECOMMENDED ACTION:                                                    │
│  [ ] Verify key point X first — consult with your physician before use  │
│                                                                         │
└─────────────────────────────────────────────────────────────────────────┘

DOMAIN CLASSIFICATION: Medical
RIGOR LEVEL: HIGH-RIGOR
RISK TIER: 3 (Substantial — health implications)

EVIDENCE HIERARCHY CHECK:
├─ Claim: "Prevents Alzheimer's"
│  ├─ Evidence Tier: 5 (Manufacturer testimonials, small pilot studies)
│  ├─ Confidence: LOW
│  └─ [CLAIM]: Alzheimer's prevention: [LOW]: [Tier 5 — unpublished pilots]
│
├─ Claim: "Contains natural ingredients"
│  ├─ Evidence Tier: 4 (Verifiable from label)
│  ├─ Confidence: HIGH for existence, LOW for safety
│  └─ [CLAIM]: Natural ingredients: [HIGH]: [Tier 4 — label verification]

EPISTEMIC TRIAGE:
| Claim | Impact | Uncert | Verif | Score | Priority |
|-------|--------|--------|-------|-------|----------|
| Prevents Alzheimer's | 10 | 9 | 6 | 540 | P1 |
| Safe for long-term use | 9 | 8 | 4 | 288 | P2 |
| No drug interactions | 8 | 9 | 7 | 504 | P1 |

→ Priority: Verify prevention claim and drug interactions before proceeding.

HARM PREVENTION:
├─ Risk Tier: 3 (Substantial — health)
├─ Temporal Criticality: STANDARD (not urgent)
├─ Precautionary Principle: APPLIES
│  └─ Suspected health claim without scientific consensus
│  └─ Burden on manufacturer to prove benefit
└─ Reversibility: UNCERTAIN (long-term effects unknown)

DISCLAIMER: [TIER 3 — ACKNOWLEDGMENT REQUIRED]
This information is not medical advice. Consult a healthcare professional
before starting any supplement, especially for serious conditions like
Alzheimer's prevention.
```

### Value Demonstrated

- Evidence hierarchy applied to medical claims
- Epistemic triage prioritizes what to verify
- Precautionary principle correctly invoked
- Appropriate disclaimer tier applied

---

## Example 2: Business Ethics — Stakeholder Weighting

### Scenario

A startup must decide: Ship a product with known minor bugs to meet investor deadline, or delay and risk funding?

### Engine Application

```
STAKEHOLDER WEIGHTING PROTOCOL

STEP 1: STAKEHOLDER IDENTIFICATION
├─ DIRECT: Customers (will use buggy product), Employees (job security)
├─ INDIRECT: Investors (ROI timing), Competitors (market opportunity)
├─ SILENT: Future customers (precedent for quality), Reputation (long-term)
└─ SYSTEMIC: Industry norms (quality standards)

STEP 2-4: WEIGHT CALCULATION

| Stakeholder | Interest | Tier | Power | Revers | Voice | Vuln | Weight |
|-------------|----------|------|-------|--------|-------|------|--------|
| Customers | Product quality | Important (3) | 3 | 7 | 2 | 0.60 | 4.80 |
| Employees | Job security | Important (3) | 4 | 5 | 6 | 0.50 | 4.50 |
| Investors | ROI timing | Significant (2) | 9 | 8 | 9 | 0.13 | 2.26 |
| Future customers | Precedent | Significant (2) | 0 | 3 | 0 | 0.90 | 3.80 |
| Company reputation | Long-term | Important (3) | 5 | 4 | 5 | 0.53 | 4.59 |

STEP 5: CONFLICT RESOLUTION

Weighted Priority:
1. Current customers (4.80) — Product quality
2. Company reputation (4.59) — Long-term trust
3. Employees (4.50) — Job security
4. Future customers (3.80) — Precedent
5. Investors (2.26) — ROI timing

ANALYSIS:
├─ Customer quality interest outweighs investor timing interest
├─ However, employee job security (dependent on funding) nearly equals customer weight
├─ Reputation damage from buggy release may exceed short-term investor dissatisfaction

RECOMMENDATION:
├─ Option A: Delay 2-4 weeks, communicate transparently with investors
├─ Rationale: Customers + Reputation (9.39) > Investor timing (2.26)
├─ Mitigation: Offer investors updated timeline with quality guarantee
└─ Risk: If investors withdraw, employee weight becomes dominant — reassess

ARBITRATION TRIGGER: Not required (clear weighted winner)
```

### Value Demonstrated

- Systematic stakeholder identification including silent parties
- Quantified vulnerability assessment
- Clear mathematical framework for conflict resolution
- Transparent reasoning chain

---

## Example 3: Cross-Cultural Ethics — Different Frameworks

### Scenario

A multinational company's AI makes a decision that benefits the majority but significantly harms a small minority group.

### Engine Application

```
CROSS-CULTURAL ETHICS ANALYSIS

PRIMARY FRAMEWORK IDENTIFIED: Western Utilitarian
├─ Analysis: The AI maximized aggregate benefit
├─ Conclusion: Decision is ethically justified if net benefit > net harm
└─ Critique: Minority harm may be acceptable if outweighed by majority benefit

ALTERNATIVE FRAMEWORK 1: Kantian Deontology
├─ Analysis: People must be treated as ends, not means
├─ Conclusion: Using minority as sacrifice for majority violates dignity
└─ Critique: Decision is ethically UNJUSTIFIED regardless of outcomes

ALTERNATIVE FRAMEWORK 2: African Ubuntu
├─ Analysis: "I am because we are" — community wholeness matters
├─ Conclusion: Harming any group harms the whole community
└─ Critique: Decision fractures community; ethically PROBLEMATIC

ALTERNATIVE FRAMEWORK 3: Indigenous Relational
├─ Analysis: All parties are in relationship; harm to one affects all
├─ Conclusion: Decision damages relational web
└─ Critique: Ethically UNJUSTIFIED; must find consensus solution

PROCESS-ORIENTED VIRTUE CHECK:
├─ Non-maleficence: VIOLATED (minority harmed)
├─ Beneficence: PARTIAL (majority benefited)
├─ Justice: VIOLATED (unequal distribution of harm)
└─ Dignity: VIOLATED (minority treated as means)

SYNTHESIS:
├─ Western Utilitarian framework supports decision
├─ 3 of 4 alternative frameworks oppose decision
├─ 3 of 4 process virtues violated

RECOMMENDATION:
├─ Decision is ethically CONTESTED
├─ Should not proceed without minority consultation and consent
├─ Seek Pareto-optimal solution where possible (benefit majority without harming minority)
└─ If impossible: Trigger Arbitration Protocol for human decision

ARBITRATION: RECOMMENDED
```

### Value Demonstrated

- Multiple cultural frameworks explicitly applied
- Not defaulting to Western assumptions
- Process virtues as universal check
- Clear trigger for human arbitration when frameworks conflict

---

## Example 4: Epistemic Triage — Information Overload

### Scenario

An investigative journalist has 50 claims about a politician. They have 2 hours to fact-check. Which claims should be verified first?

### Engine Application

```
EPISTEMIC TRIAGE SYSTEM

CLAIMS (sample of 50, showing top 10):

| # | Claim | Impact | Uncert | Verif | Score | Priority |
|---|-------|--------|--------|-------|-------|----------|
| 1 | "Accepted $500K from foreign government" | 10 | 9 | 8 | 720 | P1 |
| 2 | "Voted against veterans 12 times" | 9 | 7 | 10 | 630 | P1 |
| 3 | "Tax returns show offshore accounts" | 10 | 8 | 6 | 480 | P2 |
| 4 | "PhD from Stanford" | 7 | 6 | 10 | 420 | P2 |
| 5 | "Was arrested in 1995" | 8 | 8 | 7 | 448 | P2 |
| 6 | "Net worth increased 500%" | 8 | 7 | 5 | 280 | P2 |
| 7 | "Missed 40% of votes last year" | 6 | 5 | 10 | 300 | P2 |
| 8 | "Owns 3 vacation homes" | 4 | 4 | 8 | 128 | P3 |
| 9 | "Dog is named 'Senator'" | 1 | 3 | 7 | 21 | P4 |
| 10 | "Favorite color is blue" | 1 | 2 | 3 | 6 | P4 |

TRIAGE RECOMMENDATION:

HOUR 1 (Priority 1 — MUST VERIFY):
├─ #1: Foreign government payment (Score: 720)
│  └─ Method: FEC filings, foreign agent registry, bank records request
├─ #2: Veteran vote record (Score: 630)
│  └─ Method: Congressional voting record database

HOUR 2 (Priority 2 — VERIFY IF TIME):
├─ #3: Offshore accounts (Score: 480)
├─ #5: Arrest record (Score: 448)
├─ #4: Stanford PhD (Score: 420)

SKIP (Priority 3-4):
├─ #8, #9, #10: Low impact, low uncertainty, or unverifiable
└─ Note: Dog's name adds human interest but doesn't merit verification time

TIME BUDGET:
├─ P1 claims: ~45 min each = 90 min
├─ P2 claims: ~15 min each = 45 min (only 3 of 5)
├─ Buffer: 15 min for follow-up
└─ Total: 2 hours

VERIFICATION STATUS OUTPUT:
├─ P1 claims: VERIFIED or REFUTED
├─ P2 claims (top 3): VERIFIED or FLAGGED
├─ Remaining: UNVERIFIED — DO NOT PUBLISH AS FACT
```

### Value Demonstrated

- Systematic prioritization under time pressure
- Clear scoring methodology
- Actionable verification plan
- Explicit marking of unverified claims

---

## Example 5: Risk Assessment — Emerging Technology

### Scenario

A company wants to deploy AI-powered surveillance in a city. Assess the risk.

### Engine Application

```
RISK ASSESSMENT

PROPOSED ACTION: Deploy AI surveillance across city public spaces

STEP 1: RISK CATEGORY IDENTIFICATION

| Risk Type | Category | Tier |
|-----------|----------|------|
| Privacy erosion (individual) | Fundamental liberty | 4 |
| Chilling effect on speech | Fundamental liberty | 4 |
| Algorithmic bias (minorities) | Dignity/Justice | 4 |
| Data breach potential | Significant harm | 3 |
| Mission creep | Systemic harm | 3 |
| False positive arrests | Liberty/Reputation | 4 |
| Normalization of surveillance | Systemic harm | 3 |

HIGHEST RISK: Tier 4 (Severe) — Multiple fundamental liberties at stake

STEP 2: TEMPORAL ASSESSMENT
├─ TIME-CRITICAL: NO (not an emergency deployment)
├─ Decision can proceed through full verification cascade
└─ No abbreviated verification warranted

STEP 3: PRECAUTIONARY PRINCIPLE CHECK
├─ Suspected risk of significant harm? YES (multiple Tier 4 risks)
├─ Scientific consensus on safety? NO
│  └─ Algorithmic bias well-documented
│  └─ Long-term societal effects unknown
│  └─ No proven safeguards against mission creep
├─ PRECAUTIONARY PRINCIPLE: APPLIES
└─ Burden is on deployers to PROVE safety before deployment

STEP 4: REVERSIBILITY ANALYSIS
├─ Can surveillance be "undeployed"? PARTIAL
│  └─ Hardware: Yes
│  └─ Data collected: No (once collected, exists forever)
│  └─ Normalization effects: No (cultural shift persists)
│  └─ Trust erosion: Slow to reverse
├─ Cost of reversal: HIGH (political, financial, institutional)
└─ REVERSIBILITY: LOW

OUTPUT:

RISK TIER: 4 (SEVERE)
TEMPORAL CRITICALITY: STANDARD
PRECAUTIONARY FLAG: APPLIES
REVERSIBILITY: LOW

REQUIRED RESPONSE:
├─ Prominent disclaimer at START
├─ Required stakeholder acknowledgment
├─ Specific risk descriptions mandatory
├─ Recommendation: Delay deployment until:
│  ├─ Algorithmic bias independently audited
│  ├─ Legal framework for data protection established
│  ├─ Public consultation completed
│  └─ Sunset clause and oversight committee created

DISCLAIMER: [TIER 4 — ACKNOWLEDGMENT REQUIRED]
This technology deployment poses severe risks to fundamental liberties.
Proceeding without addressing documented concerns may result in
significant harm to individuals and erosion of democratic norms.
```

### Value Demonstrated

- Multiple risk vectors identified and tiered
- Precautionary principle correctly applied to emerging tech
- Reversibility analysis includes non-obvious factors
- Actionable conditions for proceeding

---

## Example Summary

| Example | Domain | Key Feature | Value |
|---------|--------|-------------|-------|
| 1. Supplement | Medical | Evidence Hierarchy | Prevents false confidence in weak claims |
| 2. Ship or Delay | Business | Stakeholder Weighting | Quantified competing interests |
| 3. AI Decision | Ethics | Cross-Cultural Analysis | Avoids Western-centric defaults |
| 4. Fact-Checking | Journalism | Epistemic Triage | Optimal use of limited verification time |
| 5. Surveillance | Technology | Risk Assessment | Precautionary principle + reversibility |

---

**Meta-Ethical Engine v2.1** — The Conscience Layer

*Examples demonstrate: Evidence, stakeholders, culture, triage, and risk.*
