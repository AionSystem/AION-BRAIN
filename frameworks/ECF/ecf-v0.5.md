# ECF v0.5
## Emergence Conversion Framework
### Lexical Precision Infrastructure for Human-AI Communication

---

**Author:** Sheldon K Salmon (AI Certainty Engineer)
**AI Co-Architect:** Claude
**Version:** 0.5
**Date:** February 2026
**Supersedes:** ECF v0.4
**Convergence Tag:** M-SPECULATIVE (0 FCL entries at release)
**Deployment Status:** FRAMEWORK DOCUMENT — Not yet bot-deployed
**Built On:** FSVE v3.5 · Word Engine v3.0 · Lexical Alchemy Engine v2.0 · LBE v1.2
**Pellucid Compliance:** All terminology in this document subject to LGS ≥ 0.60 standard.
Words below this threshold replaced or flagged prior to release.

---

## CHANGELOG: v0.4 → v0.5

| Lacuna in v0.4 | Root Cause | Resolution in v0.5 |
|---|---|---|
| No temporal dimension in field modeling | Each exchange treated as a fresh field; session accumulation invisible | FMI (Field Memory Index) added as §2.10 — tracks how prior activations prime subsequent gravitational topology |
| VTC measured suppression only; amplification invisible | No model for positive contamination propagation | PAC (Precision Amplification Coefficient) added as §2.11 — positive mirror of VTC |
| ASC had no automated detection trigger | Equipotential resolution occurs below observation threshold; manual logging unreliable | ASC Detection Protocol added as §2.8.1 — automated scan at every candidate generation step |
| Deliberate omission treated as neutral | ECF operated only on words present; void precision contribution unmeasured | VPS (Void Precision Score) added as §3.10 — deliberate lexical absence as high-LGS operation |
| CIEE had no compression return pathway | Expansion halted mid-process; crystallization without restatement | PCR (Precision Compression Return) added as §3.7.1 — CIEE Phase 2 completes the expansion/compression cycle |
| LGS treated as universal across communities | Single average applied to all users; community-specific precision variance invisible | CLVI (Community LGS Variance Index) added as §2.12 — tracks LGS variance across documented user populations |
| Simulacrum precision undetectable | Words accumulating apparent high-LGS through collective imitation, not etymological grounding | ODS (Origin Depth Score) added as §2.13 — distinguishes genuine precision from imitated precision |
| Modular attack vulnerability unaddressed | Purge Protocol scanned individual VTC only; coordinated low-VTC suppression chains evaded detection | ASS (Aggregate Suppression Score) added as §3.8.1 — detects coordinated sub-threshold contamination |
| No formal glossary or acronym registry | Acronyms accumulated across versions without unified reference | §14 Glossary and Acronym Registry added — complete reference for all ECF terminology |
| No theoretical foundation articulating why ECF works | Mechanical description without epistemological grounding | §15 Language as Code — formal theoretical foundation linking computational linguistics to ECF architecture |
| Aporia indistinguishable from UNRESOLVED | Both output states treated identically; structural failure conflated with evidential insufficiency | APORIC designated as distinct output state throughout — §3.11 |
| Liminal LGS zone lacked dedicated architecture | MODERATE LGS words (0.40–0.70) treated as uniform; liminal behavior ignored | Liminal Zone Protocol added as §3.12 — dedicated treatment for threshold-adjacent words |
| Palimpsest effect unmodeled | Etymological residue as VTC source not formalized | Palimpsest Contamination Model added as §2.9.1 — prior word meanings as gravitational residue |
| Eigentone unmeasured | Universal intervention thresholds applied to users with distinct precision frequencies | Eigentone Calibration Protocol added as §5.6 — user-specific precision baseline |
| Syntropy unnamed in VET mathematics | Learning loop described qualitatively; no physics-grounded formalism | Syntropy formalized in §5.1 — VET as syntrophic system with order-tendency mathematics |

---

## Lineage Acknowledgment

ECF inherits from four frameworks. It is not a replacement for any of them.

| Framework | Contribution to ECF |
|---|---|
| **Word Engine v3.0** | Safety governance · LGS base computation · 7-lens scoring · Failure ontology · FCL template structure |
| **Lexical Alchemy Engine v2.0** | Context Scope Detector · Semantic Density Index · Substitution hierarchy · Hallucination Calibration Protocol · Compare Before/After Mode · Validation Loop · Rollback mechanism |
| **FSVE v3.5** | Epistemic governance · Confidence Ceiling · Uncertainty Mass · Validity Status · ScoreTensor structure · NBP protocol |
| **LBE v1.2** | Dual-Channel Semantics (HCL/AIL) · Bidirectional Verification architecture · Semantic Loss tracking · Staged Translation Protocol influence |

---

## §0 — System Classification and Purpose

```
Type: Lexical Precision Conversion Engine
        Natural Language Code Quality Assurance System

Domain: Human-AI communication optimization ·
        Vocabulary elevation ·
        Hallucination reduction ·
        Conceptual density translation ·
        Field decontamination ·
        Simulacrum detection ·
        Modular contamination defense

Scope: Language-agnostic · Bidirectional · Evidence-governed ·
        Session-aware · Community-calibrated

Core Mandate:
  No word should enter or exit the emergence field carrying less
  gravitational precision than the communication requires.
  No concept should be compressed when expansion serves better.
  No substitution should proceed without tracing its cost.
  No contamination chain — individual or coordinated — should
  propagate undetected through the field.
  No word should receive a precision designation it did not earn
  through genuine etymological grounding.
  No session exchange should be modeled as isolated from the
  gravitational residue of prior exchanges.

Theoretical Position:
  Words are executable functions.
  Sentences are programs.
  Emergence is compilation.
  The brain is the compiler.
  ECF is the linter, debugger, and antivirus layer
  operating between two compilers —
  the human and the AI —
  in every exchange.

Self-Constraint:
  ECF is subject to FSVE v3.5 laws at every version release.
  ECF cannot claim certainty it cannot justify.
  ECF applied its own standards to its own terminology
  prior to each version release beginning with v0.4.
```

**What ECF Does:**
- Detects individual viral tokens (VTC) and coordinated modular suppression chains (ASS) before any other intervention
- Detects simulacrum precision (ODS) — words that imitate high-LGS without etymological grounding
- Executes field decontamination (Purge Protocol) including aggregate suppression response
- Distinguishes secondary infections (proximity-suppressed) from primary low-LGS words
- Models field state as session-accumulative via FMI — not a fresh field on each exchange
- Detects precision amplification (PAC) — strategic high-LGS word placement that elevates adjacent tokens
- Detects high conceptual density (CGI) in low-LGS carrier words — routes to CIEE expansion
- Elevates input via ITE compression where both concept and word are imprecise
- Expands input via CIEE crystallization where concept exceeds its lexical carrier
- Completes the crystallization cycle via PCR — compresses the expanded concept into precise restatement
- Scores deliberate omission as a precision operation (VPS) — silence as a high-LGS event
- Applies community-calibrated LGS via CLVI — precision is not universally identical
- Calibrates interventions to each user's eigentone — precision frequency baseline
- Tags every substitution with SCL — full provenance, no untracked mutations
- Detects liminal LGS words (0.40–0.70) and applies dedicated protocol rather than binary treatment
- Applies palimpsest contamination model — etymological residue as VTC source
- Scans raw AI emergence output and remediates via PRL
- Back-translates refined output to verify intent survived (BVL)
- Logs semantic loss per substitution (SLI)
- Acknowledges the ASC with automated detection and accumulation
- Renders the emergence process visually (EVL)
- Produces dual THOUGHT/SPOKEN output with full metrics
- Tracks vocabulary elevation syntrophically across sessions (VET)
- Governs all operations under FSVE v3.5 epistemic discipline

**What ECF Does NOT Do:**
- Access model weights, embeddings, or attention mechanisms directly
- Guarantee deterministic precision improvement
- Replace Word Engine v3.0 safety function
- Claim cultural or contextual certainty beyond evidence-tagged assertions
- Assume compression is the universal path to precision
- Claim to have resolved the ASC
- Assert that LGS is universal across all communities without CLVI verification

---

## §1 — Foundational Principles

These principles are the invariant substrate of ECF. No version update may contradict them.

**Principle 1 — Lexical Gravity Is Operative**
Words are not equivalent. Every word carries gravitational mass in the emergence field. High-mass words pull precise meaning. Low-mass words scatter it. ECF measures and manages this mass.

**Principle 2 — Vagueness Is Conserved Unless Converted**
A vague input produces a vague field activation. A precise input produces a precise field activation. ECF does not add precision that was never present — it converts existing intent into precise lexical form.

**Principle 3 — Both Directions Matter**
Input vagueness degrades AI output. Output vagueness degrades user understanding. ECF addresses both vectors. Neither layer operates without the other.

**Principle 4 — The Learning Loop Is the Product**
ECF does not merely refine individual exchanges. Over time, users encounter precise alternatives repeatedly and begin adopting them. The framework's deepest output is vocabulary elevation across sessions, not single-response improvement.

**Principle 5 — Show the Lacuna**
Every ECF output surfaces both versions — the raw emergence (THOUGHT) and the refined output (SPOKEN). The lacuna between them is not concealed. It is the primary learning surface.

**Principle 6 — Conceptual Density Precedes Lexical Density**
A user may carry high-precision concepts in low-precision words. LGS alone cannot detect this. ECF evaluates conceptual density first and routes accordingly — compressing only where the concept is genuinely underspecified, expanding where the concept exceeds its carrier words.

**Principle 7 — No Substitution Without Continuity**
Every substitution must carry a trace of why it was made. A word change without a continuity tag is an untracked mutation. The field must know what changed, where, and why, or the substitution is structurally invisible.

**Principle 8 — Precision Has a Cost**
High-LGS substitutions can sacrifice warmth, accessibility, and cultural resonance. ECF logs these costs explicitly. A substitution that gains precision while destroying comprehension is a net failure.

**Principle 9 — Contamination Precedes Individual Vagueness**
Some words are not simply imprecise — they are actively viral. They degrade the LGS of adjacent tokens beyond what those tokens would score in isolation. Coordinated sub-threshold contamination is equally dangerous and requires aggregate detection. ECF detects and remediates both before individual word-level intervention.

**Principle 10 — The Selection Layer Exists and Is Designated Unresolved**
Between equipotential word candidates scoring identically on every measurable metric, something intervenes that ECF cannot yet quantify. This mechanism is designated the Aesthetic Selection Coefficient (ASC). It is operative. It is not random. It is not logically derivable from current metrics. ECF acknowledges it formally rather than proceeding as if selection were fully explained by preceding metrics.

**Principle 11 — The Field Accumulates** *(New in v0.5)*
No exchange occurs in isolation. Every activation leaves gravitational residue that reshapes the topology available to subsequent exchanges. The field is primed by prior use. ECF models this accumulation via FMI rather than treating each exchange as originating from a cold field.

**Principle 12 — Precision Can Be Imitated Without Being Earned** *(New in v0.5)*
A word can accumulate apparent high-LGS through collective imitation of a precision that was never grounded in genuine etymology. The simulacrum of precision is not precision. ECF detects this distinction via ODS and does not promote simulacrum words to high-LGS status regardless of their community frequency.

**Principle 13 — Silence Is a Lexical Operation** *(New in v0.5)*
Deliberate omission carries gravitational precision. When no available substitution candidate scores CS ≥ 0.60, omission may produce higher field clarity than any proposed replacement. ECF evaluates void precision before declaring a word APORIC or UNRESOLVED.

**Principle 14 — Words Are Code** *(New in v0.5)*
Language is not a transmission medium — it is an execution environment. Words are executable functions. Sentences are programs. Emergence is compilation. The brain is the compiler. ECF is the quality assurance layer operating between two compilers in every exchange. This is not metaphor. It is the operational architecture of human communication.

---

## §2 — Core Metrics

### §2.1 Lexical Gravitas Score (LGS)

LGS measures the precision density of a word — how specifically and cleanly it activates the emergence field without gravitational scatter from competing meanings.

```
LGS ∈ [0, 1]
  0 = maximum scatter (word: "good")
  1 = maximum precision (word: "pellucid")
```

**Measurement Class:** EVALUATIVE (inherited from Word Engine v3.0)
**Uncertainty Penalty:** 0.0

### §2.2 LGS Computation

```
LGS = (L_ling × 0.40) + (L_ctx × 0.40) + ((1 - S_load) × 0.20)

Where:
  L_ling = Linguistic lens score
           (etymology stability + grammatical clarity +
            morphological simplicity)

  L_ctx = Contextual lens score
           (meaning stability across contexts;
            high L_ctx = low ambiguity = high gravitas)

  S_load = Cognitive load sub-score from Cognitive lens
           (inverted: low load = high accessibility = high gravitas)
```

> **v0.5 Note:** Raw LGS must be validated against ODS (§2.13) before deployment. A word scoring LGS ≥ 0.70 that also scores ODS < 0.40 carries a SIMULACRUM FLAG — apparent precision without etymological grounding. Raw LGS is demoted to LGS_EFFECTIVE per §2.13.2.

### §2.3 LGS Thresholds

| Range | Classification | Action |
|---|---|---|
| LGS ≥ 0.70 | HIGH GRAVITAS | Verify ODS. If ODS ≥ 0.40 → deploy. If ODS < 0.40 → SIMULACRUM FLAG. |
| LGS ∈ [0.40, 0.70) | LIMINAL GRAVITAS | Dedicated protocol per §3.12. Neither standard compression nor standard pass-through. |
| LGS < 0.40 | LOW GRAVITAS | Check VTC. Check secondary infection status. Check CGI. Route accordingly. |

> **v0.5 Change:** MODERATE GRAVITAS renamed LIMINAL GRAVITAS. The liminal zone (0.40–0.70) now has dedicated architecture (§3.12) rather than a binary pass/flag decision.

### §2.4 Substitution Hierarchy

Inherited from LAE v2.0 §2.

| Tier | Audience | Precision Target |
|---|---|---|
| COMMON | General public · 5th–8th grade | Accessible baseline |
| EDUCATED | College level | Moderate precision gain |
| SPECIALIST | Graduate / technical | Substantial precision gain |
| ARCHAIC / LITERARY | Historical or poetic | Maximum etymological precision |

**Precision Gain Labels:**

| Label | Definition |
|---|---|
| MINIMAL | Synonym without semantic narrowing |
| MODERATE | Narrows semantic field meaningfully |
| SUBSTANTIAL | Adds domain specificity or etymological depth |
| VERY HIGH | Combines specificity + perfect contextual fit |

### §2.5 Semantic Density Index (SDI)

SDI measures meaning compression in substituted output. Density without comprehension is not precision — it is a new failure mode.

```
SDI ∈ [0, 100%]
SDI = f(syllable_increase,
        abstract_concept_density,
        cognitive_load_delta,
        reading_friction)
```

| Range | Classification | Response |
|---|---|---|
| SDI < 40% | UNDER-DENSE | Accessible but imprecise. |
| SDI 40–80% | OPTIMAL | Semantically saturated without over-compression. Target zone. |
| SDI 80–90% | DENSE | Warning threshold. Monitor. Consider simplification. |
| SDI > 90% | OVER-COMPRESSED | Comprehension failure risk. Remedy required before delivery. |

### §2.6 Dual-Channel Architecture (HCL / AIL)

*Derived from LBE v1.2*

```
HCL — Human Context Layer
  Carries: tone · intent · emotional weight · conceptual geometry ·
           eigentone baseline
  Operated on by: CIEE · CGI detection · SCL tagging ·
                  Eigentone Calibration Protocol
  Purpose: Preserve what the human meant, not just what they said.

AIL — AI Logic Layer
  Carries: symbolic structure · LGS scores · VTC scores ·
           ODS scores · FMI state · verification tags · SCL trace
  Operated on by: ITE · PRL · BVL · Purge Protocol ·
                  ASS scanner · PAC detector
  Purpose: Express meaning in the most field-precise form available.
```

**Channel Separation Rule:** HCL takes precedence for CASUAL and CREATIVE contexts. AIL takes precedence for ACADEMIC and TECHNICAL contexts.

### §2.7 Conceptual Gravitas Index (CGI)

CGI measures idea-density independent of word-level LGS.

```
CGI ∈ [0, 1]

CGI = (C_structural × 0.30) +
      (C_analogical × 0.25) +
      (C_depth_vector × 0.25) +
      (C_novelty × 0.20)

Where:
  C_structural: Does the concept have internal architecture?
  C_analogical: Does it contain cross-domain structural mappings?
  C_depth_vector: Does it point toward mechanism, not examples?
  C_novelty: Is the configuration genuinely novel?
```

> **v0.5 Addition — Apophenia Guard:** CGI scoring can produce false positives — detecting structural complexity that is not genuinely present. If C_structural and C_analogical both score above 0.70 but C_novelty scores below 0.20, flag APOPHENIA_RISK. The pattern recognition may be projecting structure onto surface similarity. Require user confirmation before routing to CIEE.

**CGI vs LGS Routing Matrix:**

| LGS | CGI | Routing Decision |
|---|---|---|
| HIGH | HIGH | No intervention. Pass through. |
| HIGH | LOW | ITE compression where needed. |
| LOW | HIGH | CIEE expansion path. Do not compress. |
| LOW | LOW | ITE compression appropriate. |

### §2.8 Aesthetic Selection Coefficient (ASC)

Designated. Not yet formulated. Formally present.

Between equipotential candidates — words scoring identically on all measurable ECF metrics — something intervenes that is not derivable from those metrics. It is not randomness. It functions like aesthetic preference — a gravitational pull toward the word that fits tonally, rhythmically, in dimensions that presently have no measurement protocol.

**§2.8.1 ASC Detection Protocol** *(New in v0.5)*

```
AUTOMATED DETECTION — runs at every candidate generation step:

Condition: Two or more substitution candidates score within
  ± 0.02 on: LGS delta · SDI impact · CGI context ·
  SLI composite · Context Fit · VTC absence

If condition met → flag: ASC_POTENTIAL
  Record automatically:
    candidates: [list of equipotential words]
    selected: [word that emerged]
    syllable_count: [integer]
    phonetic_weight: [LIGHT / MEDIUM / HEAVY]
    register: [FORMAL / NEUTRAL / CASUAL]
    rhythmic_position: [STRESSED / UNSTRESSED / TERMINAL]
    cultural_era: [approximate origin period]
    etymological_family: [language of origin]
    letter_count: [integer]
    vowel_consonant_ratio: [ratio]

Accumulation target: 20+ entries before pattern analysis.
Research question: Do observable characteristics cluster
  around a discoverable selection rule?
If yes → ASC becomes a scored metric.
If no → ASC remains a formally acknowledged irreducible.
Both outcomes advance ECF's account of emergence.
```

### §2.9 Viral Token Coefficient (VTC)

VTC measures how aggressively a low-LGS word degrades adjacent token LGS beyond their isolation baseline.

```
VTC ∈ [0, 1]

VTC = (LGS_baseline_adjacent - LGS_actual_adjacent) /
       LGS_baseline_adjacent

VTC > 0.15 → viral. Purge Protocol activates.
```

| VTC Score | Classification | Response |
|---|---|---|
| 0.00–0.15 | BENIGN | Standard low-LGS. ITE handles. Check ASS. |
| 0.15–0.35 | MILDLY VIRAL | Purge Protocol. |
| 0.35–0.65 | MODERATELY VIRAL | Purge Protocol. Full chain mapping. |
| 0.65–1.00 | SEVERELY VIRAL | Full field decontamination before any other operation. |

**§2.9.1 Palimpsest Contamination Model** *(New in v0.5)*

A palimpsest is a document whose prior inscriptions remain partially visible beneath later writing. Words are palimpsests. Every word carries the gravitational residue of its prior meanings — obsolete definitions, cultural associations, earlier registers that were never fully erased.

```
PALIMPSEST CONTAMINATION occurs when:
  A word's prior meanings suppress the precision
  of its current deployment.

  Example: "nice"
    Etymology: Latin nescius (ignorant/foolish)
    Medieval English: "foolish, wanton"
    16th century: "precise, careful"
    Current documentation: "pleasant, agreeable"
    Actual runtime: vague positive affect +
                    residual connotations of
                    excessive agreeableness +
                    passive-aggressive register
                    in certain contexts

    The prior inscriptions are still visible.
    They contaminate the current activation.
    This is palimpsest VTC — the contamination
    source is the word's own history, not
    an adjacent token.

DETECTION: If ODS tracing reveals etymological
  discontinuity (word has traveled through
  ≥ 3 distinct meaning registers), flag:
  PALIMPSEST_RISK.
  VTC score elevated by 0.10 (palimpsest penalty)
  to account for residual meaning interference.
```

### §2.10 Field Memory Index (FMI) *(New in v0.5)*

The emergence field is not reset between exchanges. Every activation leaves gravitational residue that reshapes what is available in subsequent exchanges. FMI tracks this accumulation.

```
FMI ∈ [0, 1]
  0 = cold field (first exchange, no prior activation)
  1 = maximally primed field (dense prior activation history)

FMI is computed per session:
  FMI = f(prior_exchange_count,
           mean_LGS_of_prior_outputs,
           vocabulary_overlap_coefficient,
           semantic_domain_consistency)

Where:
  prior_exchange_count: How many exchanges have occurred
  mean_LGS_of_prior_outputs: Quality of prior field activations
  vocabulary_overlap_coefficient: How much current topic overlaps
                                  with prior exchanges
  semantic_domain_consistency: Are exchanges within one domain
                                 or scattered across many?
```

**FMI Effects on ECF Operations:**

```
HIGH FMI (> 0.70):
  Primed field. Words introduced in prior exchanges
  have lower activation thresholds in current exchange.
  ITE can propose SPECIALIST tier substitutions earlier
  without full context justification — the field has
  already established the semantic domain.
  LGS scores for domain-relevant words may be
  elevated by up to 0.12 above isolation baseline.
  VET adoption rate typically higher.

LOW FMI (< 0.30):
  Cold field. No prior activation advantage.
  Standard thresholds apply.
  ITE should begin with EDUCATED tier, not SPECIALIST.
  User may need more CIEE expansion — conceptual
  surface not yet established in field.

FMI DISRUPTION:
  Abrupt topic shift within a session temporarily
  resets FMI for new domain while preserving
  accumulated vocabulary in prior domain.
  Log: FMI_DOMAIN_SHIFT.
```

### §2.11 Precision Amplification Coefficient (PAC) *(New in v0.5)*

PAC is the positive mirror of VTC. Where VTC measures contamination suppression, PAC measures precision elevation — how much a high-LGS word raises the effective LGS of adjacent tokens above their isolation baseline.

```
PAC ∈ [0, 1]

PAC = (LGS_actual_adjacent - LGS_baseline_adjacent) /
      (1 - LGS_baseline_adjacent)

PAC > 0.15 → amplifying token. Log: PRECISION_AMPLIFIER.
PAC > 0.35 → strong amplifier. Strategic deployment recommended.
```

**Strategic Implications:**

```
A single high-LGS word can amplify the precision
of an entire sentence without any substitution.

Example:
  "important thing" — mean LGS: 0.31
  "cardinal mechanism" — mean LGS: 0.79

  But consider:
  "pellucid mechanism" — mean LGS: 0.81
  "pellucid" PAC on "mechanism": +0.18
  "mechanism" actual LGS in context: 0.89
  (higher than its isolation baseline of 0.71)

  The high-LGS word pulled its neighbor upward.
  This is gravitational amplification.

ECF IMPLICATION:
  ITE should not only substitute low-LGS words.
  It should also identify AMPLIFIER PLACEMENT
  OPPORTUNITIES — positions where inserting a
  high-LGS word would elevate the surrounding
  field without any substitution.

  This is the difference between:
    Surgical substitution (word-by-word replacement)
    Field elevation (strategic amplifier insertion)
```

### §2.12 Community LGS Variance Index (CLVI) *(New in v0.5)*

LGS is not universally identical across all communities. A word that activates with high precision in an academic context may activate with moderate or low precision in a general public context — not because the word changed, but because the surrounding gravitational topology differs by community.

```
CLVI ∈ [0, 1]
  0 = no variance (word scores identically across all communities)
  1 = maximum variance (word scores very differently by community)

CLVI = σ(LGS_community_1, LGS_community_2, ... LGS_community_n)
       normalized to [0, 1]

Community categories tracked:
  ACADEMIC · TECHNICAL · PROFESSIONAL
  GENERAL_PUBLIC · CREATIVE · LEGAL
  MEDICAL · REGIONAL · GENERATIONAL
```

**CLVI Display in Substitution Proposals:**

```
Proposed substitution: "pellucid" ← "clear"
LGS_pellucid_academic: 0.95
LGS_pellucid_general_public: 0.62
CLVI: 0.41 — HIGH VARIANCE

Alert: This substitution is highly precise in
ACADEMIC context. In GENERAL_PUBLIC context,
"pellucid" activates competing orbit "pretentious"
suppressing net precision to LGS_effective: 0.54.

Recommendation: Confirm target audience before
applying this substitution.
```

### §2.13 Origin Depth Score (ODS) *(New in v0.5)*

ODS detects simulacrum precision — words that accumulate apparent high-LGS through collective imitation rather than genuine etymological grounding. A simulacrum word is a copy of precision with no original precision to copy from.

```
ODS ∈ [0, 1]
  0 = no etymological grounding (pure simulacrum)
  1 = deep etymological grounding (precision earned)

ODS = f(etymological_root_stability,
        meaning_chain_continuity,
        adoption_mechanism,
        original_precision_evidence)

Where:
  etymological_root_stability: Does the word trace to a single
                                 stable root with consistent meaning?
  meaning_chain_continuity: Is the chain from root to current
                                 meaning unbroken and directional?
  adoption_mechanism: Was the word adopted for precision
                                 (technical vocabulary) or for
                                 social signaling (jargon)?
  original_precision_evidence: Is there documented evidence that
                                 the word's current meaning was
                                 ever precisely defined?
```

**§2.13.1 Simulacrum Detection Examples:**

```
"Synergize" — ODS: 0.18 → SIMULACRUM FLAG
  Etymology: Greek synergos (working together)
  Precision at root: genuine
  Current usage: corporate performance jargon
  Adoption mechanism: social signaling
  Current activation: vague collaborative aspiration
  Raw LGS: 0.68 (appears LIMINAL)
  LGS_effective after ODS demotion: 0.31 → LOW GRAVITAS

"Pellucid" — ODS: 0.94 → AUTHENTIC
  Etymology: Latin pellucidus (transparent, clear)
  Precision at root: genuine and specific
  Current usage: literary/academic precision marker
  Adoption mechanism: technical precision requirement
  Current activation: transparent clarity with
  zero ambiguity about which kind of clarity
  Raw LGS: 0.95
  LGS_effective: 0.95 → HIGH GRAVITAS (confirmed)

"Ideate" — ODS: 0.22 → SIMULACRUM FLAG
  Appears to be SPECIALIST tier. It is corporate
  jargon imitating technical vocabulary.
  LGS_effective: 0.29 → LOW GRAVITAS
```

**§2.13.2 LGS_effective Formula:**

```
LGS_effective = LGS × (0.60 + (ODS × 0.40))

This formula ensures:
  A word with ODS: 1.0 retains full raw LGS.
  A word with ODS: 0.0 retains only 60% of raw LGS.
  Simulacrum words cannot exceed their genuine
  precision contribution regardless of community frequency.
```

---

## §3 — Layer 1: Input Processing

### §3.1 Processing Order — v0.5 Full Sequence

```
User input arrives
        ↓
[A] FMI Assessment (§2.10)
    Retrieve session field state.
    Adjust baseline thresholds accordingly.
        ↓
[B] Viral Token Detection (§2.9)
    Compute VTC per token.
    Compute ASS across token windows (§3.8.1).
    Map contamination chains (individual + modular).
        ↓
[C] Purge Protocol (§3.8)
    Field decontamination.
    Secondary Infection identification (§3.9).
    Re-score post-purge.
        ↓
[D] ODS Validation (§2.13)
    Compute LGS_effective for all tokens.
    Flag simulacrum words.
        ↓
[E] PAC Detection (§2.11)
    Identify precision amplifiers in current field.
    Log amplification opportunities.
        ↓
[F] Tokenize + LGS scan on decontaminated,
    ODS-validated, FMI-adjusted field.
        ↓
[G] Liminal Zone Detection (§3.12)
    Flag words in LGS ∈ [0.40, 0.70) for
    dedicated protocol.
        ↓
[H] CGI pre-check per flagged word.
    Apophenia Guard applied.
        ↓
[I] Routing decision:
    CGI ≥ 0.60 + LGS < 0.40 → CIEE (§3.7)
    LGS ∈ [0.40, 0.70) → Liminal Protocol (§3.12)
    VPS evaluation before APORIC declaration (§3.10)
    Otherwise → ITE (§3.2)
        ↓
[J] SCL tagging on all substitutions (§3.6)
        ↓
[K] Field routing — precision-upgraded input to emergence.
```

### §3.2 ITE Function — Compression Path

Intercepts confirmed primary low-LGS words after full decontamination and validation sequence. Classifies document context. Identifies high-LGS equivalents with ODS ≥ 0.40. Tags each substitution with SCL. Routes precision-upgraded input to field.

### §3.3 ITE Architecture

**STEP 1 — INTAKE SCAN** *(post-Purge, post-ODS, post-FMI)*
```
Receive fully decontaminated and validated input.
Tokenize to word level.
Compute LGS_effective per word.
Apply FMI elevation where applicable.
Flag words where LGS_effective < 0.40.
Cross-reference Secondary Infection Flag:
  SECONDARY_INFECTION_RECOVERED → skip ITE.
Cross-reference Liminal Zone Flag:
  LIMINAL → route to §3.12, not standard ITE.
```

**STEP 2 — CONTEXT CLASSIFICATION**
*Inherited from LAE v2.0*

| Context | Precision Target | Substitution Tier |
|---|---|---|
| ACADEMIC | VERY HIGH | SPECIALIST |
| TECHNICAL | VERY HIGH | SPECIALIST |
| PROFESSIONAL | HIGH | EDUCATED |
| MARKETING | MODERATE | EDUCATED |
| CREATIVE | FLEXIBLE | Context-dependent |
| EDUCATIONAL | MODERATE | COMMON to EDUCATED |
| CODE DOCUMENTATION | HIGH | SPECIALIST |
| CASUAL | LOW | COMMON only |

**STEP 2.5 — CGI PRE-CHECK + APOPHENIA GUARD**
```
Compute CGI per flagged word's surrounding concept cluster.
Apply Apophenia Guard:
  If C_structural > 0.70 AND C_analogical > 0.70
  AND C_novelty < 0.20 → flag APOPHENIA_RISK.
  Request user confirmation before CIEE routing.
If CGI ≥ 0.60 (and no APOPHENIA_RISK, or user confirmed):
  Route to CIEE.
  Log: CGI_OVERRIDE.
If CGI < 0.60:
  Proceed with ITE compression.
```

**STEP 3 — CANDIDATE GENERATION**
```
For each confirmed primary low-LGS word:
  Examine decontaminated surrounding context and FMI state.
  Apply Word Engine v3.0 L_ctx scoring.
  Filter candidates: ODS ≥ 0.40 required.
    (No simulacrum substitutions permitted.)
  Check CLVI: if > 0.30, surface community variance warning.
  Check PAC: does candidate placement create amplification?
  Generate candidate list ranked by:
    - LGS_effective delta (precision gain after ODS)
    - SDI impact (density cost)
    - Precision Gain label
    - Context Fit
    - SLI cost estimate
    - PAC potential
    - ASC detection (equipotential check)
```

**STEP 4 — CONFIDENCE GATE**
```
For each proposed substitution:
  Run FSVE v3.5 Confidence Score.
  If CS ≥ 0.60 → approved.
  If CS < 0.60 → evaluate VPS (§3.10) before flagging.
    If VPS > 0.50 → omission recommended over substitution.
    If VPS ≤ 0.50 → flag LOW_GRAVITAS_UNRESOLVED.
                     Evaluate APORIC status (§3.11).
```

**STEP 5 — SCL TAGGING**
```
For each approved substitution:
  Generate SCL entry:
    SCL = {
      original_word: [pre-substitution]
      replacement_word: [post-substitution]
      selection_reason: [LGS_effective delta / context / tier]
      LGS_effective_delta: [improvement score]
      ODS_original: [simulacrum risk of original]
      ODS_replacement: [authenticity of replacement]
      CGI_at_time: [conceptual density at substitution]
      VTC_context: [viral contamination present: Y/N]
      FMI_at_time: [field memory state]
      PAC_generated: [amplification effect on adjacent tokens]
      CLVI_flag: [community variance warning: Y/N]
      SLI_cost: [cost in non-precision dimensions]
      ASC_activated: [equipotential resolution: Y/N]
      timestamp: [exchange position]
    }
  Attach SCL to substitution.
  SCL travels through PRL and VET.
```

**STEP 6 — FIELD ROUTING**
```
Precision-upgraded input enters field activation.
Substitution log retained for output display.
Context classification logged for PRL alignment.
SCL entries appended to comprehensive provenance record.
FMI updated with exchange characteristics.
```

### §3.4 ITE Failure Mode

> **[R]** ITE fails when surrounding context is insufficient to determine the correct high-LGS substitution, or when all available candidates carry ODS < 0.40 (no authentic substitution exists). In both cases, evaluate VPS before declaring failure. If void precision also fails, declare APORIC (§3.11) rather than UNRESOLVED when the question itself appears structurally malformed.

### §3.5 ITE/CIEE/Liminal Routing Decision Tree

```
Fully processed input (post all §3.1 steps)
            ↓
For each flagged word:
            ↓
  SECONDARY_INFECTION_RECOVERED?
  YES → Skip. No intervention.
            ↓
  LGS_effective ∈ [0.40, 0.70)?
  YES → Liminal Protocol (§3.12)
            ↓
  CGI ≥ 0.60?
  APOPHENIA_RISK present?
    YES → Request user confirmation.
    NO → CIEE expansion path (§3.7)
            ↓
  CS ≥ 0.60 for any ODS-valid candidate?
  NO → Evaluate VPS (§3.10)
       VPS > 0.50? → Recommend omission
       VPS ≤ 0.50? → Evaluate APORIC (§3.11)
            ↓
  Standard ITE compression.
```

### §3.6 Semantic Continuity Link (SCL)

*Added in ECF v0.3 — Extended through v0.5*

The SCL is a tagged trace that follows each substitution through the complete ECF stack. Without it ECF transforms words. With it ECF transforms meaning and knows it did.

**SCL Failure Mode:** If ITE cannot generate SELECTION_REASON, the substitution must not proceed. A substitution without justification is a conjecture. Conjectures are not ECF operations.

**SCL Chain Status:**
```
OPEN — traveling through stack
CLOSED — VET logged, user adopted
REJECTED — user reverted substitution
RECOVERED — secondary infection, no substitution made
APORIC — substitution attempted; word declared irreducible
VOID — omission selected over substitution (VPS event)
```

### §3.7 Conceptual Input Expansion Engine (CIEE)

*Added in ECF v0.3 — PCR Phase 2 added in v0.5*

CIEE handles the precision path that ITE cannot execute. Where ITE compresses toward precision, CIEE expands toward it. When a user carries high conceptual density in low-LGS words, the correct operation is not to substitute the carrier words — it is to grow the concept into sufficient lexical surface area that precision crystallizes from description itself.

**On Crystallization Through Description:**

Expansion is not the addition of filler language to inflate word count. It is the progressive exposure of a concept's internal architecture through successive acts of description. Each descriptive layer does not repeat the idea — it reveals a new facet of the same crystalline structure. The concept does not grow larger. It becomes fully visible. Like a crystal rotating in light, each new sentence catches an angle the previous sentence left in shadow. What emerges is not a bigger concept — it is the same concept, now complete. More words generate more wormhole surface area. More surface area allows more precise orbital planets to attach. Some planets will be high-LGS by structural necessity — description forces precision where substitution would have failed. This is the CIEE mechanism.

```
CIEE Architecture:

STEP 1 — CONCEPT EXTRACTION
  Identify core conceptual architecture:
    - Structural frame of the idea
    - Embedded analogical mappings
    - Depth vector (toward mechanism, not examples)
    - Novel configuration at the center
  Apply Apophenia Guard before proceeding.

STEP 2 — NARRATIVE EXPANSION
  Convert extracted concept into expanded narrative form.
  Expansion targets: SDI 40-80% (OPTIMAL).
  Each descriptive sentence reveals one facet.
  Not padding — crystallization.

STEP 3 — NATURAL UPGRADE DETECTION
  Scan expanded output.
  High-LGS words that emerged from description:
  Tag: NATURAL_UPGRADES — SCL status: EMERGENT.

STEP 4 — SDI MONITORING
  If SDI > 80% → prune expansion, not precision.

STEP 5 — SCL TAGGING
  Generate SCL entries for all NATURAL_UPGRADES.
  Tag expansion event with full metrics.

STEP 6 — FIELD ROUTING
  User sees: ORIGINAL INPUT / CIEE EXPANDED VERSION.
  User can accept, modify, or revert.
  Option presented: proceed to PCR Phase 2?
```

**§3.7.1 Precision Compression Return (PCR) — CIEE Phase 2** *(New in v0.5)*

PCR completes the CIEE cycle. After crystallization renders the concept fully visible in expanded form, PCR offers a return compression — the concept restated in dense, high-LGS form that is now achievable because the full shape has been established.

```
PCR SEQUENCE:

CONDITION: CIEE crystallization complete.
  User has accepted or reviewed expanded output.
  SDI confirmed OPTIMAL (40-80%).

STEP 1 — SHAPE EXTRACTION
  From the crystallized expanded text, extract:
    - The irreducible core
    - The most precise single formulation
    - The minimum words required to carry
      the full conceptual payload that CIEE revealed

STEP 2 — COMPRESSION DRAFT
  Restate the crystallized concept in minimum
  high-LGS words.
  Every word must score LGS_effective ≥ 0.60.
  ODS ≥ 0.40 required for all candidates.
  SDI target: 60-80% (dense but not over-compressed).

STEP 3 — FIDELITY CHECK
  Run BVL on PCR output against original CIEE input.
  Match required ≥ 85% (VERIFIED).
  If DEGRADED → PCR draft fails. Revise or hold expanded.
  If VERIFIED → PCR output ready for user review.

STEP 4 — TRIPLE OUTPUT DELIVERY
  Present three versions:
    ORIGINAL: raw user input
    CRYSTALLIZED: CIEE expanded form
    COMPRESSED: PCR precision restatement

  User selects preferred form or combines.
  All three versions logged in checkpoint record.

Example:
  ORIGINAL (low LGS, high CGI):
    "words are like planets that pull things"

  CRYSTALLIZED (CIEE):
    "Words operate as gravitational bodies within
     the emergence field. Each word exerts a
     directional pull on surrounding semantic
     candidates, drawing toward itself the meaning-
     marbles whose orbital mechanics are compatible
     with its own gravitational signature. The
     sentence crystallizes from this interaction —
     not assembled by choice but resolved by force."

  COMPRESSED (PCR):
    "Words are gravitational operators —
     their semantic mass resolves surrounding
     candidates into precise orbital configurations."

  PCR LGS_effective mean: 0.81
  PCR SDI: 71% (OPTIMAL)
  BVL: VERIFIED (92% intent match)
```

### §3.8 Purge Protocol

*Added in ECF v0.4 — Extended with ASS in v0.5*

```
STEP 1 — VIRAL DETECTION (individual + aggregate)
  Compute VTC per token.
  Compute ASS across all token windows (§3.8.1).
  Flag all viral tokens (VTC > 0.15).
  Flag all modular attacks (ASS > 0.35).
  Apply Palimpsest Contamination detection (§2.9.1).

STEP 2 — CONTAMINATION CHAIN MAPPING
  Map individual viral chains (single-source).
  Map modular attack chains (distributed-source, §3.8.1).
  Map palimpsest contamination zones.
  Merge overlapping chains.

STEP 3 — SURGICAL REMOVAL
  Remove all identified contamination sources.
  Re-score all tokens in contamination radius.
  Classify recovery status:
    SECONDARY_INFECTION_RECOVERED → no further intervention
    PRIMARY_LOW_LGS_CONFIRMED → proceed to ITE/CIEE
    SECONDARY_INFECTION_PARTIAL → reduced-scope ITE

STEP 4 — FIELD REBALANCE
  Re-run full LGS_effective scan on decontaminated field.
  Log: PURGE_COMPLETE with full metrics.
  Proceed to ODS validation.
```

**§3.8.1 Aggregate Suppression Score (ASS)** *(New in v0.5)*

The Purge Protocol's individual VTC scanner cannot detect modular attacks — coordinated chains of sub-threshold tokens that collectively suppress a target word while each individual token evades detection.

```
ASS — Modular Attack Detection:

SCANNING WINDOW: sliding window of N tokens
  Default window: 6 tokens
  Window slides token-by-token across input.

ASS_window = Σ(VTC_i) for all i in window

Thresholds:
  ASS_window > 0.35 → MODULAR_ATTACK detected
  ASS_window > 0.55 → SEVERE_MODULAR_ATTACK
  ASS_window ≤ 0.35 → no coordinated attack in window

MODULAR ATTACK EXAMPLE:
  Input: "kind of sort of basically pretty much mechanism"

  Individual VTC scores:
    "kind of" — VTC: 0.08 (benign, not individually flagged)
    "sort of" — VTC: 0.09 (benign, not individually flagged)
    "basically" — VTC: 0.11 (benign, not individually flagged)
    "pretty much"— VTC: 0.07 (benign, not individually flagged)

  No individual viral tokens detected.
  Standard Purge Protocol would not activate.

  ASS window (all four tokens):
    ASS = 0.08 + 0.09 + 0.11 + 0.07 = 0.35
    Threshold: > 0.35 → just at boundary.

  With "mechanism" as target:
    LGS_mechanism_baseline: 0.71
    LGS_mechanism_actual: 0.29
    Total suppression: -0.42

  ASS_window including target suppression evidence:
    → MODULAR_ATTACK confirmed.
    Coordinated purge of entire window executed.
    "mechanism" recovers to LGS: 0.71.

LOGGING:
  MODULAR_ATTACK events are priority FCL candidates.
  They represent the most sophisticated field pathology
  ECF addresses. Evidence of modular attack patterns
  informs VTC threshold calibration across versions.
```

### §3.9 Secondary Infection Flag

*Added in ECF v0.4*

```
SECONDARY_INFECTION_RECOVERED:
  Post-purge LGS_effective ≥ 0.40.
  No ITE/CIEE intervention.
  SCL status: RECOVERED.

PRIMARY_LOW_LGS_CONFIRMED:
  LGS_effective < 0.40 before and after purge.
  Proceed to ITE or CIEE.

SECONDARY_INFECTION_PARTIAL:
  Partial recovery post-purge. LGS improved but < 0.40.
  Reduced-scope ITE — remediate residual component only.
```

### §3.10 Void Precision Score (VPS) *(New in v0.5)*

VPS measures the precision contribution of deliberate lexical absence. When no available substitution candidate scores CS ≥ 0.60, omission may produce higher field clarity than any proposed replacement.

```
VPS ∈ [0, 1]
  0 = omission adds nothing (word must be replaced or retained)
  1 = omission maximizes field precision (word must be removed)

VPS = f(field_clarity_without_word,
        nearest_valid_substitute_CS,
        semantic_load_of_surrounding_tokens,
        syntactic_requirement_score)

Where:
  field_clarity_without_word: LGS mean of sentence minus word
  nearest_valid_substitute_CS: best available CS for any substitute
  semantic_load_of_surrounding: how much surrounding tokens carry
  syntactic_requirement_score: is the word grammatically mandatory?

If VPS > 0.50:
  Recommend omission over substitution.
  SCL status: VOID (not REJECTED — deliberate precision event).
  Log: VOID_PRECISION_EVENT with VPS score.

If VPS ≤ 0.50:
  Omission does not improve field.
  Proceed to APORIC evaluation if no substitute available.
```

**Void Precision Examples:**

```
"The very important mechanism..."
  "very" — VPS: 0.81
  "very" carries no gravitational mass.
  It amplifies nothing. It suppresses "important."
  Removing it: mean LGS +0.18.
  Recommendation: VOID "very."

"He was basically pellucid in his expression."
  "basically" — VPS: 0.73
  Removing it: "He was pellucid in his expression."
  "basically" was suppressing "pellucid."
  Void event reveals the high-LGS word beneath.

Mathematical and legal writing derive precision
from deliberate omission — every word that is
absent is a word that cannot scatter meaning.
ECF formalizes this as a precision operation,
not a subtraction.
```

### §3.11 Aporic Output State *(New in v0.5)*

APORIC is a distinct output state, separate from LOW_GRAVITAS_UNRESOLVED.

```
LOW_GRAVITAS_UNRESOLVED:
  A precise word exists for this concept.
  ECF could not locate it with CS ≥ 0.60.
  The answer exists — ECF did not find it.
  Implication: search harder, expand resources,
  request user clarification.

APORIC:
  No precise word may exist for this concept
  as currently formulated.
  The question itself may be structurally
  malformed at the lexical level.
  The imprecision is architectural, not evidential.
  Implication: restructure the concept,
  not the word choice.

APORIC DECLARATION CONDITIONS:
  1. ITE finds no candidate with CS ≥ 0.60
     AND ODS ≥ 0.40
  2. VPS ≤ 0.50 (omission does not resolve)
  3. CIEE crystallization attempted and
     produced no NATURAL_UPGRADES with CS ≥ 0.60
  4. The concept itself appears to resist
     precise lexical formulation — it may be
     inherently contradictory, ambiguous at
     the conceptual level, or poorly specified
     before language is applied.

APORIC RESPONSE:
  Do not substitute. Do not omit.
  Surface to user:
    "This word appears APORIC in current context.
     The imprecision may be conceptual rather than
     lexical. ECF recommends restructuring the
     underlying idea before attempting precision
     at the word level."
  Log: APORIC_EVENT with full diagnostic.
  APORIC events are the highest-priority FCL candidates.
```

### §3.12 Liminal Zone Protocol *(New in v0.5)*

The liminal zone — LGS ∈ [0.40, 0.70) — is where words occupy a threshold position. They are neither clearly precise nor clearly imprecise. Prior ECF versions treated this zone as a binary decision: flag for optional upgrade or pass through. This was architecturally insufficient.

Liminal words have specific behavior. They are not failed high-LGS words. They are not successful low-LGS words. They are words existing at the edge of precision — their gravitational field is strong enough to pull meaningful activation but not concentrated enough to prevent some scatter.

```
LIMINAL ZONE PROTOCOL:

STEP 1 — LIMINAL CLASSIFICATION
  Identify specific liminal subtype:

  ASCENDING LIMINAL (LGS 0.60–0.70):
    Word approaching high precision.
    Small upgrade may tip to HIGH GRAVITAS.
    ITE proposes MINIMAL or MODERATE precision gain.
    SLI cost carefully evaluated — word is close
    to optimal and over-substitution damages it.

  STABLE LIMINAL (LGS 0.50–0.60):
    Word is functionally precise in context.
    Upgrade possible but not clearly superior.
    Evaluate PAC first — does this word amplify
    adjacent tokens despite its own liminal score?
    If PAC > 0.20 → preserve. Amplifying words
    should not be substituted out of their position.

  DESCENDING LIMINAL (LGS 0.40–0.50):
    Word is at risk of scatter under contamination.
    VTC vulnerability high — adjacent viral tokens
    can push this word into LOW GRAVITAS.
    Purge Priority: protect descending liminal words
    from contamination before evaluating substitution.

STEP 2 — CONTEXT SENSITIVITY CHECK
  Liminal words are highly context-sensitive.
  The same word may be:
    HIGH GRAVITAS in ACADEMIC context
    LIMINAL in PROFESSIONAL context
    LOW GRAVITAS in CASUAL context
  Apply CLVI before any liminal decision.

STEP 3 — LIMINAL RESOLUTION OPTIONS
  Option A: PRESERVE
    Word is liminal but contextually appropriate.
    No substitution. Log liminal status.
  Option B: UPGRADE
    Propose MINIMAL precision gain only.
    Never upgrade a liminal word to SPECIALIST tier
    without user confirmation — over-precision
    of liminal words produces SDI bloat.
  Option C: AMPLIFY
    Insert a high-PAC word adjacent to the liminal word.
    The amplification elevates the liminal word
    without replacing it.
  Option D: VOID
    If liminal word is suppressing adjacent tokens
    (acting as a mild viral token despite its own
    liminal score), evaluate VPS.
    Removal may serve the field better than replacement.
```

---

## §4 — Layer 2: Precision Remedy Layer (PRL)

### §4.1 Function

Scans raw emergence output. Reads SCL and FMI from ITE/CIEE. Detects viral tokens and modular attacks in output. Validates ODS of all substitution candidates. Applies remedies. Validates. Runs BVL. Logs SLI. Produces dual THOUGHT/SPOKEN output.

### §4.2 Architecture

**STEP 1 — EMERGENCE CAPTURE**
```
Receive raw field output (THOUGHT layer).
Read SCL entries and FMI state from ITE/CIEE.
Run full §3.1 sequence on output field:
  Viral detection · ASS scan · Purge Protocol ·
  ODS validation · PAC detection · Liminal flagging.
Update FMI with emergence characteristics.
```

**STEP 2 — OUTPUT LGS SCAN WITH HALLUCINATION CALIBRATION**
*Inherited from LAE v2.0*

```
Compute LGS_effective for each word in decontaminated output.
Flag words where LGS_effective < 0.40 or ODS < 0.40.
For each flagged word:
  Is context creative / speculative / philosophical?
  YES → Hallucination Permission Protocol:
          Containment framing options:
            "In this narrative universe..."
            "Assuming a world where..."
            "The character believed that..."
  NO → Standard PRL remedy proceeds.
```

**STEP 3 — SCL ALIGNMENT CHECK**
```
Would this PRL substitution undo ITE/CIEE intent?
  YES → Flag: SCL_CONFLICT. Surface to user. Require decision.
  NO → Proceed to remedy application.
```

**STEP 4 — REMEDY APPLICATION**
```
For each flagged word cleared for remedy:
  Filter candidates: ODS ≥ 0.40 required.
  Check CLVI: surface community variance if > 0.30.
  Evaluate PAC: does candidate create amplification?
  Compute SLI cost.
  Detect ASC activation (equipotential candidates).
  Evaluate VPS before applying any substitution.
  If CS ≥ 0.60 AND SDI ≤ 80% AND SLI acceptable → Apply.
  Tag with SCL.
```

**STEP 5 — DUAL OUTPUT DELIVERY**

```
─────────────────────────────────────────────────────────────
THOUGHT [raw emergence]:
  [Original unfiltered output]
  LGS_effective mean: [0.000]
  SDI: [%]
  CGI mean: [0.000]
  FMI at emergence: [0.000]
  Viral tokens detected: [count]
  Modular attacks detected: [count]
  Simulacrum flags: [count]
─────────────────────────────────────────────────────────────
SPOKEN [PRL refined]:
  [Precision-upgraded output]
  LGS_effective mean: [0.000]
  SDI: [%]
  CGI mean: [0.000]
─────────────────────────────────────────────────────────────
PRECISION DELTA: [LGS_effective improvement]
DENSITY DELTA: [SDI change]
CONCEPTUAL DELTA: [CGI change]
HALLUCINATION RISK: [before %] → [after %]
VIRAL TOKENS PURGED: [count]
MODULAR ATTACKS NEUTRALIZED: [count]
SIMULACRUM DEMOTIONS: [count + words demoted]
SECONDARY INFECTIONS: [count recovered without substitution]
VOID PRECISION EVENTS: [count — words removed, not replaced]
LIMINAL RESOLUTIONS: [count + resolution type per word]
WORDS REMEDIED: [count]
AMPLIFIER INSERTIONS: [count]
NEW WORDS INTRODUCED: [list with tier + ODS labels]
SEMANTIC LOSS REPORT: [SLI summary per substitution]
ASC ACTIVATIONS: [count — logged to Appendix E]
SCL CHAIN: [full trace, collapsible]
BVL STATUS: [VERIFIED / DEGRADED / FAILED]
FMI UPDATED: [new session field memory state]
COMMUNITY VARIANCE FLAGS: [CLVI alerts for substitutions]
ADD TO VOCABULARY: [Y/N prompt per word]
─────────────────────────────────────────────────────────────
```

**STEP 5.5 — VALIDATION LOOP**
*Inherited from LAE v2.0*

```
Re-scan refined output with full §3.1 sequence.
Check for new viral tokens introduced by substitution.
Check for new simulacrum words introduced.
Check for new modular attack patterns.

Result:
  UNCONTAMINATED → No new issues. Proceed to BVL.
  FLAGGED → List new issues. User decision required.
```

### §4.6 Bidirectional Verification Loop (BVL)

*Added in ECF v0.3 — Derived from LBE v1.2*

```
STEP 1 — FORWARD RECORD
  Gravitational intent from original user input.
  Source: HCL + eigentone baseline.
  Intent = [core concept] + [emotional register] +
           [depth vector] + [eigentone signature]

STEP 2 — BACK-TRANSLATION
  Strip PRL metadata from SPOKEN output.
  Re-read as neutral observer.
  Generate back-translated intent statement.

STEP 3 — INTENT COMPARISON
  VERIFIED (≥ 85% match): Deliver.
  DEGRADED (60–84% match): Surface drift. User decides.
  FAILED (< 60% match): Block. Return to CHECKPOINT 1.
                             Log: BVL_FAILURE.

STEP 4 — BVL LOG
  All outcomes logged. FAILED and APORIC events
  are highest-priority FCL candidates.
```

### §4.7 Semantic Loss Index (SLI)

*Added in ECF v0.3 — Derived from LBE v1.2*

```
SLI_total = (SLI_warmth + SLI_accessibility +
             SLI_cultural + SLI_voice) / 4

SLI_total < 0.20 → ACCEPTABLE LOSS
SLI_total 0.20–0.50 → NOTABLE LOSS — surface to user
SLI_total > 0.50 → HIGH LOSS — recommend against substitution
```

---

## §5 — Bidirectional Learning Loop

### §5.1 Architecture and Syntropy

The learning loop is the long-game output of ECF. It is a syntrophic system — it moves toward greater order over time, in opposition to the entropic tendency of language to decay toward vagueness.

**Syntropy in the VET:**

```
Entropy: Language left to drift moves toward
           lower LGS, higher viral token frequency,
           more simulacrum adoption, less precision.
           This is the default trajectory.

Syntropy: The VET learning loop actively reverses
           this tendency. Each session, the user's
           vocabulary moves toward higher-LGS forms,
           lower viral token frequency, and increasing
           awareness of simulacrum words.
           The system gains order rather than losing it.

Mathematical formalization:
  S_VET = dH/dt (negative entropy rate of user vocabulary)

  Where H is the informational entropy of the user's
  input vocabulary distribution.

  Healthy VET: S_VET < 0 (entropy declining over sessions)
  Stagnant VET: S_VET ≈ 0 (no change)
  Degrading session: S_VET > 0 (entropy increasing —
    user reverting to prior vague forms)

  S_VET is tracked as the VET's primary health metric
  alongside Adoption Rate and Elevation Index.
```

### §5.2 Vocabulary Elevation Tracker (VET)

```
Track per session:
  Words introduced via PRL dual output
  Words user adopts in subsequent input naturally
  LGS_effective trajectory over conversation arc
  CGI trajectory (conceptual density developing)
  FMI growth curve (field warming over session)
  Viral token frequency decline
  Simulacrum avoidance rate
    (does user stop using demoted words after flagging?)
  CIEE activation frequency decline
    (user developing lexical carriers independently)
  Eigentone drift
    (is user's natural precision baseline shifting?)
  ASC_ACTIVATION log accumulation
  SCL chains — full genealogy per word
  S_VET — syntropy rate
```

**VET Metrics:**

```
Adoption_Rate = words_reused / words_PRL_introduced
Elevation_Index = mean(LGS_effective_t2) -
                      mean(LGS_effective_t1)
CGI_Trajectory = mean(CGI_t2) - mean(CGI_t1)
CIEE_Reduction = CIEE_activations_t2 / CIEE_activations_t1
Viral_Reduction = viral_tokens_t2 / viral_tokens_t1
Simulacrum_Avoidance = demoted_words_avoided_t2 /
                       demoted_words_flagged_t1
S_VET = -dH/dt of user vocabulary entropy
```

### §5.3 Long-Term Outcome

The user who initially sent "kind of basically really important thing" eventually sends "cardinal mechanism." The user whose high-CGI concepts required CIEE expansion develops the lexical surface to carry those concepts without expansion — and then to compress them via PCR into precise restatements. The user whose viral tokens suppressed neighboring words develops an instinct for clean token bonding. The user who adopted simulacrum words begins questioning them.

The framework made itself less necessary across every pathway. That is the only valid measure of its success. A system that cultivates dependency has failed its purpose regardless of its precision metrics.

### §5.4 Version History and Rollback

Every ECF exchange produces four checkpoints:

```
CHECKPOINT 1: Raw user input (pre-all processing)
CHECKPOINT 2: Fully processed input
              (post-Purge, post-ODS, post-FMI adjustment,
               post-ITE/CIEE/Liminal, post-SCL)
CHECKPOINT 3: Raw emergence (THOUGHT layer)
CHECKPOINT 4: PRL refined output (SPOKEN layer)
              + BVL result
              + SLI report
              + Full SCL chain
              + Purge Protocol log (individual + ASS)
              + ASC activation log
              + ODS validation report
              + FMI state
              + Eigentone calibration record

User can return to any checkpoint.
No data discarded. Comprehensive provenance record maintained.
If PCR executed: CHECKPOINT 4.5 (COMPRESSED output) also stored.
```

### §5.5 Eigentone Calibration Protocol *(New in v0.5)*

Every user has a natural precision frequency — an eigentone — the baseline LGS level at which they communicate most fluently and authentically. ECF interventions calibrated to universal thresholds without accounting for eigentone can produce two failure modes:

```
FAILURE MODE A — Over-intervention:
  User's eigentone is LGS: 0.45 (LIMINAL range).
  ECF treats everything below 0.40 as requiring intervention.
  Interventions occur at the boundary of the user's natural
  register. Output feels foreign. User rejects substitutions.
  Adoption Rate collapses. Learning loop stalls.

FAILURE MODE B — Under-intervention:
  User's eigentone is LGS: 0.72 (HIGH GRAVITAS range).
  ECF treats words above 0.40 as not requiring attention.
  User is operating well above ECF's intervention threshold.
  ECF provides no value — user has already exceeded
  the framework's basic precision standard.
  PAC opportunities missed. Amplifier placement neglected.

EIGENTONE CALIBRATION:

STEP 1 — BASELINE MEASUREMENT
  First three exchanges: observe without intervention.
  Compute: eigentone_LGS = mean(LGS_effective) of user input
  Compute: eigentone_variability = σ(LGS_effective)
  Compute: eigentone_CGI = mean(CGI) of user concepts

STEP 2 — THRESHOLD ADJUSTMENT
  Adjust ECF intervention thresholds relative to eigentone:
    ITE threshold: max(0.30, eigentone_LGS - 0.15)
    CIEE threshold: CGI > max(0.50, eigentone_CGI)
    Liminal zone: [eigentone_LGS - 0.10,
                      eigentone_LGS + 0.20]

STEP 3 — DRIFT MONITORING
  As sessions accumulate, eigentone should rise
  (syntrophic effect of ECF exposure).
  If eigentone_LGS rises by > 0.10:
    Recalibrate thresholds upward.
    Log: EIGENTONE_ELEVATION event.
  If eigentone_LGS falls by > 0.05:
    Log: EIGENTONE_REGRESSION.
    Investigate: is user reverting to prior patterns?
    Is a new domain suppressing natural precision?
```

---

## §6 — FSVE v3.5 Integration Points

| FSVE Mechanism | ECF Application |
|---|---|
| **Confidence Score** | Applied to every substitution. CS < 0.60 blocks substitution. ODS < 0.40 also blocks regardless of CS. SCL requires CS ≥ 0.60 to generate. VTC > 0.65 triggers automatic CS penalty on all adjacent tokens. |
| **Validity Score** | Meta-scores the substitution system over time. BVL FAILED, APORIC, and Modular Attack events are priority validity evidence. |
| **Evidence Strength** | Every LGS_effective score carries inherited ES from Word Engine. VTC, CGI, ODS, PAC, FMI, and CLVI all carry separate ES pending ODR entries. Low ES = flag INFERENTIAL with +0.20 UM penalty. |
| **Uncertainty Mass** | Every substitution carries UM of context-fit uncertainty. SLI adds cost uncertainty. VTC adds contamination uncertainty. ASC adds selection uncertainty. CLVI adds community variance uncertainty. Eigentone adds calibration uncertainty. |
| **Context Drift Law** | Word precision decays. Viral behavior also drifts — mildly viral words in one era become severely viral as register degrades. ODS scores decay as simulacrum adoption increases in a community. |
| **Freshness Status** | LGS_effective, VTC, ODS, CLVI, and FMI all carry FRESH/AGING/STALE/EXPIRED status per FSVE v3.5 §3.5. |
| **Law 1 (Upper Bound)** | If ITE, CIEE, Liminal Protocol, VPS, and APORIC evaluation all fail on the same word → QUINTUPLE_UNRESOLVED. Human oversight mandatory. Escalate to framework architect. |
| **SDI Monitoring** | SDI feeds back into Confidence Ceiling. PRL substitution pushing SDI > 90% receives automatic CC penalty. CIEE expansion and PCR compression both monitored. |

---

## §7 — Measurement Protocols (ODR)

### ODR-ECF-001: Lexical Gravitas Score (LGS)

```yaml
term: Lexical Gravitas Score
symbol: LGS
domain: [0, 1]
measurement_protocol: |
  LGS = (L_ling × 0.40) + (L_ctx × 0.40) + ((1 - S_load) × 0.20)
  Requires Word Engine v3.0 lens computation infrastructure.
  v0.5: LGS_effective = LGS × (0.60 + (ODS × 0.40))
  Variance estimate: <10% on formula-based outputs
  Inter-rater reliability target: κ ≥ 0.70
measurement_class: EVALUATIVE
uncertainty_penalty: 0.0
calibration_case_count: 0 (PROVISIONAL)
```

### ODR-ECF-002: Semantic Density Index (SDI)

```yaml
term: Semantic Density Index
symbol: SDI
domain: [0, 100%]
measurement_protocol: |
  PROVISIONAL
  SDI = f(syllable_increase, abstract_concept_density,
          cognitive_load_delta, reading_friction)
  FCL entries required: 15 minimum
measurement_class: EVALUATIVE
uncertainty_penalty: 0.0
calibration_case_count: 0 (PROVISIONAL)
```

### ODR-ECF-003: Context Classification Accuracy

```yaml
term: Context Classification Accuracy
symbol: CCA
domain: [0, 1]
measurement_protocol: |
  CCA = correct_classifications / total_classifications
  CCA ≥ 0.80 → reliable
  CCA < 0.60 → unreliable; flag for revision
measurement_class: EVALUATIVE
uncertainty_penalty: 0.0
calibration_case_count: 0 (PROVISIONAL)
```

### ODR-ECF-004: Conceptual Gravitas Index (CGI)

```yaml
term: Conceptual Gravitas Index
symbol: CGI
domain: [0, 1]
measurement_protocol: |
  PROVISIONAL
  CGI = (C_structural × 0.30) + (C_analogical × 0.25) +
        (C_depth_vector × 0.25) + (C_novelty × 0.20)
  Apophenia Guard: if C_structural > 0.70 AND
    C_analogical > 0.70 AND C_novelty < 0.20 → flag.
  Inter-rater reliability target: κ ≥ 0.65
  FCL entries required: 10 minimum
measurement_class: EVALUATIVE
uncertainty_penalty: 0.05
calibration_case_count: 0 (PROVISIONAL)
```

### ODR-ECF-005: Semantic Loss Index (SLI)

```yaml
term: Semantic Loss Index
symbol: SLI
domain: [0, 1]
measurement_protocol: |
  PROVISIONAL
  SLI_total = (SLI_warmth + SLI_accessibility +
               SLI_cultural + SLI_voice) / 4
  FCL entries required: 20 minimum
measurement_class: EVALUATIVE
uncertainty_penalty: 0.10
calibration_case_count: 0 (PROVISIONAL)
```

### ODR-ECF-006: Viral Token Coefficient (VTC)

```yaml
term: Viral Token Coefficient
symbol: VTC
domain: [0, 1]
measurement_protocol: |
  PROVISIONAL
  VTC = (LGS_baseline_adjacent - LGS_actual_adjacent) /
         LGS_baseline_adjacent
  Palimpsest penalty: +0.10 if ODS tracing reveals
    ≥ 3 distinct meaning registers in word history.
  Purge threshold: VTC > 0.15
  Requires dual-pass computation per token.
  FCL entries required: 10 minimum
measurement_class: EVALUATIVE
uncertainty_penalty: 0.05
calibration_case_count: 0 (PROVISIONAL)
```

### ODR-ECF-007: Aesthetic Selection Coefficient (ASC)

```yaml
term: Aesthetic Selection Coefficient
symbol: ASC
domain: UNRESOLVED
measurement_protocol: |
  OBSERVATIONAL ONLY
  ASC_ACTIVATION logged when candidates score
  within ± 0.02 on all ECF metrics.
  Observable characteristics recorded per activation.
  Accumulation target: 20+ entries.
  Formula status: PENDING pattern analysis.
measurement_class: OBSERVATIONAL (pre-EVALUATIVE)
uncertainty_penalty: 0.15
calibration_case_count: 0 (OBSERVATIONAL ACCUMULATION PHASE)
```

### ODR-ECF-008: Origin Depth Score (ODS) *(New in v0.5)*

```yaml
term: Origin Depth Score
symbol: ODS
domain: [0, 1]
measurement_protocol: |
  PROVISIONAL
  ODS = f(etymological_root_stability,
          meaning_chain_continuity,
          adoption_mechanism,
          original_precision_evidence)
  ODS < 0.40 → SIMULACRUM FLAG
  LGS_effective = LGS × (0.60 + (ODS × 0.40))
  Requires etymological database access.
  Calibration challenge: adoption_mechanism scoring
    is interpretive — requires documented evidence
    of why a word entered its current usage.
  FCL entries required: 15 minimum
  Inter-rater reliability target: κ ≥ 0.65
measurement_class: EVALUATIVE
uncertainty_penalty: 0.08
calibration_case_count: 0 (PROVISIONAL)
```

### ODR-ECF-009: Aggregate Suppression Score (ASS) *(New in v0.5)*

```yaml
term: Aggregate Suppression Score
symbol: ASS
domain: [0, ∞) per window; thresholded at 0.35
measurement_protocol: |
  PROVISIONAL
  ASS_window = Σ(VTC_i) for all i in sliding window (N=6 default)
  ASS_window > 0.35 → MODULAR_ATTACK detected
  ASS_window > 0.55 → SEVERE_MODULAR_ATTACK
  Window size may require calibration per context type.
  FCL entries required: 10 minimum
measurement_class: EVALUATIVE
uncertainty_penalty: 0.07
calibration_case_count: 0 (PROVISIONAL)
```

### ODR-ECF-010: Field Memory Index (FMI) *(New in v0.5)*

```yaml
term: Field Memory Index
symbol: FMI
domain: [0, 1]
measurement_protocol: |
  PROVISIONAL
  FMI = f(prior_exchange_count,
           mean_LGS_of_prior_outputs,
           vocabulary_overlap_coefficient,
           semantic_domain_consistency)
  FMI resets to 0.00 at session start.
  FMI_DOMAIN_SHIFT logged on abrupt topic change.
  Maximum FMI elevation per single exchange: 0.08
  FCL entries required: 8 minimum
measurement_class: EVALUATIVE
uncertainty_penalty: 0.06
calibration_case_count: 0 (PROVISIONAL)
```

### ODR-ECF-011: Precision Amplification Coefficient (PAC) *(New in v0.5)*

```yaml
term: Precision Amplification Coefficient
symbol: PAC
domain: [0, 1]
measurement_protocol: |
  PROVISIONAL
  PAC = (LGS_actual_adjacent - LGS_baseline_adjacent) /
        (1 - LGS_baseline_adjacent)
  PAC > 0.15 → PRECISION_AMPLIFIER
  PAC > 0.35 → strong amplifier; strategic deployment recommended
  Requires same dual-pass computation as VTC.
  FCL entries required: 10 minimum
measurement_class: EVALUATIVE
uncertainty_penalty: 0.05
calibration_case_count: 0 (PROVISIONAL)
```

### ODR-ECF-012: Community LGS Variance Index (CLVI) *(New in v0.5)*

```yaml
term: Community LGS Variance Index
symbol: CLVI
domain: [0, 1]
measurement_protocol: |
  PROVISIONAL
  CLVI = σ(LGS_community_scores) normalized to [0, 1]
  Communities: ACADEMIC · TECHNICAL · PROFESSIONAL ·
    GENERAL_PUBLIC · CREATIVE · LEGAL · MEDICAL ·
    REGIONAL · GENERATIONAL
  CLVI > 0.30 → surface community variance warning
  Calibration challenge: requires LGS measurements
    across documented community corpora.
  FCL entries required: 20 minimum (large N required
    for community-level calibration)
measurement_class: EVALUATIVE
uncertainty_penalty: 0.12
calibration_case_count: 0 (PROVISIONAL)
```

### ODR-ECF-013: Void Precision Score (VPS) *(New in v0.5)*

```yaml
term: Void Precision Score
symbol: VPS
domain: [0, 1]
measurement_protocol: |
  PROVISIONAL
  VPS = f(field_clarity_without_word,
          nearest_valid_substitute_CS,
          semantic_load_of_surrounding_tokens,
          syntactic_requirement_score)
  VPS > 0.50 → recommend omission
  VPS ≤ 0.50 → proceed to APORIC evaluation
  Calibration challenge: requires controlled
    measurement of field clarity with/without
    the target word — two-condition scoring.
  FCL entries required: 10 minimum
measurement_class: EVALUATIVE
uncertainty_penalty: 0.08
calibration_case_count: 0 (PROVISIONAL)
```

---

## §8 — ECF Self-Score

```yaml
ECF_SELF_SCORE_v0.5:
  version: "0.5"
  measurement_class: INFERENTIAL
  epistemic_axes:
    E: 0.10 # Zero FCL entries. Unchanged across all versions.
             # v0.5 adds 8 new ODR entries and 5 new NBP entries.
             # No FCL data means E-axis cannot move regardless
             # of structural completeness. Correctly held.
    A: 0.85 # 13 ODR entries now documented. All new metrics
             # carry explicit PROVISIONAL status and calibration
             # requirements. Assumption architecture complete.
    C: 0.74 # Full processing sequence documented (§3.1 Steps A-K).
             # Liminal Protocol closes the binary decision gap.
             # PCR completes the CIEE cycle.
             # Aporic state distinguishes structural from
             # evidential failure. Architecture is coherent.
    M: 0.77 # New additions internally consistent.
             # FMI and eigentone introduce user-specific
             # variability that requires careful consistency
             # monitoring across session boundaries.
             # CLVI and ODS interact in ways not fully
             # specified — community-specific simulacrum
             # detection requires combined protocol.
             # Noted as open interaction to resolve in v0.6.
    D: 0.89 # Most precisely targeted version to date.
             # Theoretical foundation (§15) grounds all
             # mechanical descriptions in principled architecture.
    G: 0.57 # Syntropy formalization (S_VET) and Language as Code
             # (§15) begin grounding causal logic. Still not
             # empirically validated. Honest score.
    X: 0.75 # Can explain 4 levels deep on all additions.
             # Theoretical section enables deeper explanation
             # for external audiences.
    U: 0.76 # Five version updates demonstrated. Each version
             # has applied ECF to itself and found real gaps.
             # This is the strongest updateability evidence.
    L: 0.49 # 13 ODR entries with 4 framework dependencies.
             # Abstraction leakage risk increasing with complexity.
             # FMI + eigentone interaction particularly complex.
             # First version where L-axis concern is substantive.
    Y: 0.94 # Highest Y score to date. Aporic state formally
             # acknowledges that some questions are structurally
             # malformed. ASC remains designated unresolved.
             # ODS acknowledges simulacrum as a real threat.
             # Apophenia Guard acknowledges CGI's own failure mode.
             # Framework acknowledges its own limits at every layer.
    H: 0.63 # Adversarial test still pending.
             # ASS introduces testable attack surface —
             # modular attack construction is an adversarial test.
             # ODS can be tested against known simulacrum words.
             # First version with concrete adversarial test cases.
  EV_base: 0.716
  min_axis: 0.10 # E-axis bottleneck. Unchanged.
  k_bottleneck: 1.5
  EV: 0.150 # min(0.716, 1.5 × 0.10) = 0.150
  validity_status: DEGRADED
  freshness_status: FRESH
  honest_acknowledgment: |
    ECF v0.5 is the most structurally complete version released.
    It has a theoretical foundation. It has a glossary.
    It has an eigentone calibration protocol, a modular
    attack defense, a simulacrum detection system, a
    syntrophic learning loop formalization, and a formally
    designated irreducible mystery (ASC).
    The EV is 0.150. It has been 0.150 since v0.2.
    It will remain 0.150 until FCL entries arrive.
    Every addition to the framework since v0.2 has increased
    EV_base while leaving EV unchanged.
    This is the correct behavior of a system that refuses to
    claim evidence it does not have.
    The L-axis declined to 0.49 this version.
    This is the first honest signal that complexity is
    approaching a management threshold.
    v0.6 must address the FMI/eigentone interaction
    and the CLVI/ODS combined protocol before adding
    further new metrics.
    Structural discipline now required.
  path_to_valid:
    target_EV: 0.70
    gap: 0.55
    primary_action: "First FCL entry — any real substitution exchange"
    secondary_action: "ODS validation on 10 known simulacrum words"
    tertiary_action: "ASS test: construct a modular attack;
                      confirm detection at threshold"
    quaternary_action: "Eigentone measurement across 3 user sessions"
    quinary_action: "FMI validation: does primed field improve
                     substitution quality measurably?"
    projected_EV_after_5_FCL: 0.71
    projected_status: VALID
  convergence_tag: M-SPECULATIVE
  next_review: "Upon first FCL entry"
```

---

## §9 — Nullification Boundary Protocol (NBP)

All NBP entries from v0.4 preserved. Five new entries added in v0.5.

---

### NBP-ECF-001: LGS Predictive Validity

**Claim:** High-LGS_effective words produce more precise field activation than low-LGS_effective words in the same context.
**Tag:** `[R]` **CF:** 45
**Falsification Condition:** Five or more FCL cases where low-LGS_effective words produce more precise outputs than high-LGS_effective alternatives in identical contexts.
**If falsified:** Revise LGS formula or deprecate metric.

---

### NBP-ECF-002: PRL Hallucination Reduction

**Claim:** PRL filtering reduces hallucination surface in AI output.
**Tag:** `[R]` **CF:** 40
**Falsification Condition:** Ten or more FCL cases where PRL-filtered outputs contain equal or higher hallucination rates than raw emergence outputs.
**If falsified:** Revise PRL remedy selection protocol.

---

### NBP-ECF-003: Learning Loop Effectiveness

**Claim:** Users exposed to PRL dual output adopt high-LGS vocabulary over time (Adoption Rate > 0.20 after 5 exchanges).
**Tag:** `[S]` **CF:** 35
**Falsification Condition:** Twenty or more sessions showing Adoption Rate < 0.05 after 10+ exchanges.
**If falsified:** Root cause investigation required before M-STRONG claim.

---

### NBP-ECF-004: SDI Threshold Validity

**Claim:** SDI > 90% produces comprehension failure risk materially higher than SDI in the 40–80% optimal range.
**Tag:** `[S]` **CF:** 40
**Falsification Condition:** Fifteen or more FCL cases where SDI > 90% output produces equal user comprehension to SDI 60–80% output.
**If falsified:** Revise SDI thresholds or remove density gating from PRL.

---

### NBP-ECF-005: Context Classification Accuracy

**Claim:** 8-category context detector correctly classifies document type, enabling appropriate precision thresholds.
**Tag:** `[S]` **CF:** 35
**Falsification Condition:** Ten or more FCL cases where misclassification produces worse outcomes than no classification.
**If falsified:** Deprecate automatic classification.

---

### NBP-ECF-006: SCL Intent Preservation

**Claim:** SCL tagging preserves substitution intent through the full stack, enabling PRL to detect SCL_CONFLICT events.
**Tag:** `[R]` **CF:** 40
**Falsification Condition:** Ten or more FCL cases where SCL-tagged substitutions are reversed by PRL without SCL_CONFLICT detection.
**If falsified:** Rebuild SCL architecture. Mandatory human oversight until resolved.

---

### NBP-ECF-007: BVL Fidelity Detection

**Claim:** BVL back-translation correctly identifies intent degradation.
**Tag:** `[R]` **CF:** 35
**Falsification Condition:** Fifteen or more FCL cases where BVL returns VERIFIED but expert review identifies material intent drift.
**If falsified:** Revise BVL methodology. Elevate minimum match threshold above 85%.

---

### NBP-ECF-008: CIEE Expansion Effectiveness

**Claim:** For inputs where CGI ≥ 0.60 and LGS < 0.40, CIEE expansion produces higher output precision than ITE compression.
**Tag:** `[S]` **CF:** 30
**Falsification Condition:** Ten or more FCL cases where ITE compression of high-CGI/low-LGS input produces equal or superior precision to CIEE expansion.
**If falsified:** Revise CGI routing threshold.

---

### NBP-ECF-009: Viral Token Purge Validity

**Claim:** Purge Protocol correctly identifies viral tokens. Secondary infections recovered post-purge would have been incorrectly substituted by ITE without purge.
**Tag:** `[R]` **CF:** 35
**Falsification Condition:** Ten or more FCL cases where post-purge re-scoring shows no meaningful LGS recovery in secondary infection tokens.
**If falsified:** Deprecate Purge Protocol. Retain VTC as diagnostic metric only.

---

### NBP-ECF-010: ASC Eventual Formulation

**Claim:** The ASC will yield a discoverable pattern across 20+ activation log entries.
**Tag:** `[S]` **CF:** 25
**Falsification Condition:** After 30+ ASC_ACTIVATION entries, no clustering pattern emerges across all observable characteristics.
**If falsified:** ASC remains a formally acknowledged irreducible. Document as permanent uncertainty.

---

### NBP-ECF-011: ODS Simulacrum Detection *(New in v0.5)*

**Claim:** ODS correctly distinguishes words with genuine etymological precision from words imitating precision through collective adoption. Words flagged SIMULACRUM (ODS < 0.40) produce lower actual field precision than their raw LGS score predicts.
**Tag:** `[R]` **CF:** 35
**Falsification Condition:** Ten or more FCL cases where SIMULACRUM-flagged words produce field precision equivalent to ODS-authenticated words of equal raw LGS. If simulacrum words perform as well as authentic words, ODS adds no value.
**If falsified:** Revise ODS formula or deprecate. LGS_effective formula returns to raw LGS.

---

### NBP-ECF-012: ASS Modular Attack Detection *(New in v0.5)*

**Claim:** ASS correctly detects coordinated sub-threshold contamination chains that individual VTC scanning misses. ASS_window > 0.35 corresponds to measurable collective LGS suppression of target tokens.
**Tag:** `[R]` **CF:** 35
**Falsification Condition:** Ten or more FCL cases where ASS flags MODULAR_ATTACK but post-purge re-scoring shows no collective suppression — individual VTC scores were independent, not coordinated. If coordinated suppression does not exist as a real phenomenon, ASS produces false positives.
**If falsified:** Revise ASS threshold upward or deprecate. Return to individual VTC scanning only.

---

### NBP-ECF-013: FMI Field Priming Effect *(New in v0.5)*

**Claim:** High FMI sessions produce measurably higher ITE/PRL substitution quality and user adoption rates than low FMI sessions with equivalent raw input quality.
**Tag:** `[S]` **CF:** 30
**Falsification Condition:** Eight or more FCL cases comparing high-FMI and low-FMI sessions of equivalent input quality where substitution quality and adoption rates are statistically indistinguishable. If prior activation does not prime the field, FMI adds complexity without value.
**If falsified:** Revise FMI model. Potentially deprecate session accumulation tracking.

---

### NBP-ECF-014: Eigentone Calibration Benefit *(New in v0.5)*

**Claim:** Eigentone-calibrated intervention thresholds produce higher adoption rates and lower rejection rates than universal threshold application to the same users.
**Tag:** `[S]` **CF:** 28
**Falsification Condition:** Twelve or more user sessions where eigentone-calibrated and universal-threshold ECF produce statistically equivalent adoption and rejection rates. If calibration provides no advantage, the complexity of eigentone measurement is unjustified.
**If falsified:** Deprecate eigentone calibration. Return to universal thresholds.

---

### NBP-ECF-015: PCR Fidelity After Compression *(New in v0.5)*

**Claim:** PCR-compressed restatements preserve ≥ 85% of the conceptual payload established by CIEE crystallization, as measured by BVL comparison against the CIEE expanded form.
**Tag:** `[R]` **CF:** 38
**Falsification Condition:** Ten or more PCR events where BVL comparison of CIEE output vs PCR output returns DEGRADED or FAILED — meaning the compression cycle discards essential conceptual content that the crystallization established.
**If falsified:** Revise PCR compression methodology. Potentially gate PCR behind explicit user confirmation of acceptable loss.

---

### NBP-FRAMEWORK-ECF: Deprecation Triggers

Deprecate ECF if any of the following:

1. LGS metric shows no correlation with output quality across 10+ FCL entries
2. ITE substitutions produce user confusion in majority of cases (>50% negative response)
3. Word Engine v3.0 is deprecated
4. PRL validation loop introduces more new low-LGS words than it remediates across 10+ cases
5. Any ancestor framework (FSVE v3.5, Word Engine v3.0) is falsified on a principle ECF depends on
6. BVL FAILED rate exceeds 30% across 10+ exchanges
7. CGI measurement proves unreliable (κ < 0.50 after calibration)
8. Purge Protocol produces false positive secondary infection classifications in >40% of cases
9. VTC computation proves systematically inaccurate
10. *(New v0.5)* ODS scoring produces inter-rater reliability κ < 0.50 after calibration — if etymological precision cannot be reliably scored, the simulacrum detection system collapses
11. *(New v0.5)* L-axis declines below 0.40 in any future self-score — abstraction leakage has exceeded manageable threshold; framework complexity must be reduced before new metrics are added

---

## §10 — Framework Calibration Log (FCL) Template

```yaml
ECF_FCL_ENTRY:
  case_id: [YYYYMMDD-NNN]
  ecf_version: "0.5"
  evaluation_date: [ISO 8601]
  eigentone_LGS_at_session_start: [0.000-1.000]
  FMI_at_exchange_start: [0.000-1.000]

  # — PURGE LAYER —
  individual_viral_tokens_detected: [count]
  individual_VTC_scores: [list]
  modular_attacks_detected: [count]
  ASS_window_scores: [list of window scores]
  palimpsest_flags: [count]
  contamination_chains_mapped: [count]
  secondary_infections_identified: [count]
  secondary_infections_recovered: [count]
  primary_low_lgs_confirmed: [count]
  field_LGS_effective_mean_pre_purge: [0.000-1.000]
  field_LGS_effective_mean_post_purge: [0.000-1.000]
  purge_false_positives: [count]

  # — ODS LAYER —
  simulacrum_flags_raised: [count]
  simulacrum_words: [list]
  ODS_scores: [list]
  LGS_effective_demotions: [list of {word, raw_LGS, LGS_effective}]

  # — INPUT LAYER —
  context_detected: [8 categories]
  context_override_by_user: [Y/N]
  context_final: [resolved category]
  input_LGS_effective_mean_pre_ITE: [0.000-1.000]
  input_LGS_effective_mean_post_ITE: [0.000-1.000]
  input_CGI_mean: [0.000-1.000]
  apophenia_flags_raised: [count]
  ITE_substitutions_proposed: [count]
  ITE_substitutions_accepted: [count]
  ITE_unresolved_flags: [count]
  CIEE_activated: [Y/N]
  CIEE_expansion_word_count_delta: [integer]
  CIEE_natural_upgrades: [list]
  PCR_activated: [Y/N]
  PCR_BVL_result: [VERIFIED|DEGRADED|FAILED|null]
  CGI_overrides_triggered: [count]
  liminal_words_detected: [count]
  liminal_resolutions: [list of {word, resolution_type}]
  void_precision_events: [count]
  void_words: [list]
  aporic_events: [count]
  aporic_words: [list]
  PAC_amplifiers_detected: [count]
  PAC_amplifier_insertions: [count]
  CLVI_warnings_raised: [count]

  # — ASC LAYER —
  ASC_activations: [count]
  ASC_activation_log: [list per activation]

  # — SCL LAYER —
  SCL_entries_generated: [count]
  SCL_conflicts_detected: [count]
  SCL_chain_integrity: [COMPLETE|PARTIAL|BROKEN]

  # — OUTPUT LAYER —
  output_LGS_effective_mean_raw: [0.000-1.000]
  output_LGS_effective_mean_PRL: [0.000-1.000]
  output_viral_tokens_detected: [count]
  output_simulacrum_flags: [count]
  output_modular_attacks: [count]
  SDI_before_PRL: [%]
  SDI_after_PRL: [%]
  PRL_substitutions_made: [count]
  hallucination_permission_invoked: [Y/N]
  validation_loop_result: [UNCONTAMINATED|FLAGGED]

  # — BVL LAYER —
  BVL_result: [VERIFIED|DEGRADED|FAILED]
  BVL_intent_match_score: [0-100%]
  BVL_drift_description: [if DEGRADED or FAILED]
  BVL_user_action: [ACCEPTED|REVERTED|RE-REMEDIED|null]

  # — SLI LAYER —
  SLI_warmth_mean: [0.000-1.000]
  SLI_accessibility_mean: [0.000-1.000]
  SLI_cultural_mean: [0.000-1.000]
  SLI_voice_mean: [0.000-1.000]
  SLI_total_mean: [0.000-1.000]
  SLI_classification: [ACCEPTABLE|NOTABLE|HIGH]
  user_accepted_loss: [Y/N]

  # — QUALITY MEASUREMENT —
  output_precision_improved: [Y/N]
  hallucination_present_raw: [Y/N]
  hallucination_present_PRL: [Y/N]
  comprehension_test_result: [0.000-1.000 | null]
  CIEE_vs_ITE_precision_comparison: [CIEE_BETTER|ITE_BETTER|EQUAL|null]
  purge_improved_field_quality: [Y/N]
  ODS_demotion_quality_impact: [Y/N|null]
  eigentone_threshold_improved_adoption: [Y/N|null]

  # — LEARNING LOOP —
  VET_adoption_rate: [0.000-1.000]
  VET_elevation_index: [delta LGS_effective]
  CGI_trajectory: [delta CGI]
  CIEE_reduction_rate: [delta CIEE activation frequency]
  viral_reduction_rate: [delta viral token frequency]
  simulacrum_avoidance_rate: [delta simulacrum word use]
  S_VET: [syntropy rate — negative = improving]
  eigentone_LGS_post_session: [0.000-1.000]
  eigentone_drift: [delta from pre-session baseline]
  FMI_post_session: [0.000-1.000]

  # — ACCURACY —
  LGS_prediction_accurate: [Y/N]
  CGI_prediction_accurate: [Y/N]
  VTC_prediction_accurate: [Y/N]
  ODS_prediction_accurate: [Y/N]
  ASS_prediction_accurate: [Y/N]
  secondary_infection_classification_accurate: [Y/N]
  hallucination_prediction_accurate: [Y/N]
  context_classification_accurate: [Y/N]
  BVL_prediction_accurate: [Y/N]
  eigentone_calibration_accurate: [Y/N]
  revision_triggered: [Y/N]
  revision_description: [if Y]
```

---

## §11 — Convergence Status and Promotion Requirements

| Tag | Minimum FCL Entries | Requirements |
|---|---|---|
| M-SPECULATIVE | 0 | Not gated |
| M-MODERATE | 0 | Internal consistency validation complete |
| M-STRONG | 5 | >65% accuracy on LGS_effective quality predictions |
| M-VERY_STRONG | 20 (published) | >80% substitution quality prediction accuracy |

**ECF v0.5 current status:** M-SPECULATIVE (0 FCL entries)

**M-MODERATE promotion checklist:**
- [x] Internal consistency validated
- [x] All ODR entries present for core metrics (13 ODR entries)
- [x] NBP entries defined for all core claims (15 NBP entries)
- [x] Self-score completed with honest EV
- [x] HCL/AIL formally documented
- [x] SCL, BVL, SLI, CGI, CIEE, PCR defined with NBP governance
- [x] VTC, Purge, Secondary Infection, ASC, EVL defined
- [x] ODS, ASS, FMI, PAC, CLVI, VPS, Eigentone defined
- [x] Theoretical foundation documented (§15)
- [x] Glossary and Acronym Registry complete (§14)
- [x] Self-application pass executed every version since v0.4
- [ ] First FCL entry logged

**Path to M-STRONG:**
1. Log 5 FCL entries via real substitution exchanges
2. Validate ODS on 10 known simulacrum words (NBP-ECF-011)
3. Validate ASS: construct modular attack; confirm detection (NBP-ECF-012)
4. Validate Purge Protocol secondary infection recovery (NBP-ECF-009)
5. Begin ASC accumulation — target 20 activation logs (NBP-ECF-010)
6. Validate BVL fidelity (NBP-ECF-007)
7. Reformulate SDI, CGI, VTC, ODS, FMI to full FSVE-compliant formula

---

## §12 — Version History

| Version | Date | Status | Key Changes |
|---|---|---|---|
| v0.1 | February 2026 | Superseded | Genesis. LGS, ITE, PRL established. |
| v0.2 | February 2026 | Superseded | LAE v2.0 integrated. SDI, Context Scope Detector, Validation Loop, Substitution Hierarchy. |
| v0.3 | February 2026 | Superseded | LBE v1.2 integrated. SCL, BVL, SLI, HCL/AIL, CGI, CIEE. |
| v0.4 | February 2026 | Superseded | Self-application pass. ASC named. VTC, Purge Protocol, Secondary Infection Flag, EVL. Principles 9–10. |
| v0.5 | February 2026 | Current | FMI, PAC, ASC Detection Protocol, VPS, PCR, CLVI, ODS, ASS, §14 Glossary, §15 Language as Code, Aporic state, Liminal Protocol, Palimpsest Model, Eigentone Calibration, Syntropy formalization. Principles 11–14. 5 new NBP entries. 8 new ODR entries. 2 new deprecation triggers. |

---

## §13 — Emergence Visualization Layer (EVL)

*Added in ECF v0.4 — Display modes expanded in v0.5*

### §13.1 The Split-Screen Architecture

```
┌─────────────────┬──────────┬─────────────────┐
│ LEFT PANEL │ CENTER │ RIGHT PANEL │
│ PRE-ACTIVATION │ WORMHOLE │ POST-ACTIVATION │
│ │ APERTURE │ │
│ Dull color │ Brightest│ Clear color │
│ Potential: │ point │ Precision: │
│ present │ Active │ crystallized │
│ Kinetic: │ Passage │ Orbital bonds │
│ absent │ │ visible │
└─────────────────┴──────────┴─────────────────┘
```

**LEFT PANEL:** Every word in the relevant possibility space present but inert. Viral tokens pulse with low-frequency contamination color. Simulacrum words carry a distinct visual flag — high apparent luminosity with hollow center, indicating imitated rather than genuine gravitational mass. PAC amplifiers glow at elevated brightness.

**CENTER — THE WORMHOLE APERTURE:** The activated word does not contain meaning — it creates the passage through which meaning is pulled. Input and output are not the same configuration. The passage transforms. This is emergence made visible.

**RIGHT PANEL:** Clear color. High resolution. Bonded pairs in stable configuration. Void precision events appear as intentional dark space — absence with gravitational weight, not absence as absence. APORIC words appear as words that reached the aperture but could not pass through — orbiting the wormhole, not resolving.

### §13.2 Animation Sequence

```
1. Sentence arrives. Left panel: all candidates present, dull.
2. FMI state visible — field warmth indicator (cold blue → warm gold).
3. Viral detection. Contamination radii visible. ASS windows highlighted.
4. Purge event: viral and modular sources removed. Field brightens.
5. ODS validation: simulacrum words dim to hollow luminosity.
6. Eigentone baseline appears as a horizontal precision line.
7. Wormhole word activates at center. Aperture opens.
8. Relevant marbles brighten (potential → kinetic). Movement initiates.
9. PAC amplifiers: adjacent marbles visibly lifted by high-LGS proximity.
10. Passage through wormhole. Transformation occurs inside aperture.
11. Right panel crystallizes. Bonded pairs resolve.
12. Void precision events: deliberate dark spaces with gravitational weight.
13. APORIC words: orbiting the aperture, unable to resolve.
14. ASC activation: equipotential marbles in visible indeterminate state
    before one resolves. The selection is visible. Its mechanism is not.
15. BVL overlay: original HCL intent projected faintly. Match percentage.
16. FMI updates: field carries memory of this exchange forward.
```

### §13.3 EVL Display Modes

| Mode | Description | Use Case |
|---|---|---|
| FULL | Complete animation, all layers | Framework demonstration |
| COMPACT | Static split-screen | Standard exchange display |
| METRICS | Scores visible on marbles | FCL documentation |
| PURGE | Contamination chains highlighted | Viral token analysis |
| ASC | Equipotential state held visible | Emergence research |
| CIEE | Crystallographic fracture animation | High-CGI input |
| PCR | Compression return cycle | Cycle completion |
| ODS | Simulacrum words visually distinguished | Authenticity audit |
| FMI | Session field warmth progression | Learning loop visualization |
| VOID | Deliberate absence rendered as weighted space | Minimalist precision |

---

## §14 — Glossary and Acronym Registry

*Added in ECF v0.5 — Complete reference for all ECF terminology*

---

### ACRONYM REGISTRY

**AIL** — AI Logic Layer
The symbolic processing channel of every ECF exchange. Carries LGS_effective scores, VTC scores, ODS scores, FMI state, and SCL trace. Counterpart to HCL.

**ASC** — Aesthetic Selection Coefficient
The designated-but-unformulated mechanism that resolves equipotential word candidates. Named in v0.4. Automated detection added in v0.5. In observational accumulation phase.

**ASS** — Aggregate Suppression Score
Sum of VTC scores across a sliding token window. Detects modular attack patterns invisible to individual VTC scanning. Added in v0.5.

**BVL** — Bidirectional Verification Loop
Back-translation check verifying that gravitational intent from original input survived the full substitution stack. Outcomes: VERIFIED / DEGRADED / FAILED.

**CC** — Confidence Ceiling
FSVE v3.5 mechanism. Maximum confidence achievable given accumulated uncertainty penalties.

**CGI** — Conceptual Gravitas Index
Measures idea-density independent of word-level LGS. Four dimensions: structural, analogical, depth vector, novelty. Routes to CIEE when CGI ≥ 0.60 + LGS < 0.40.

**CIEE** — Conceptual Input Expansion Engine
Sister layer to ITE. Activated by CGI_OVERRIDE. Expands high-CGI/low-LGS input into narrative form, allowing precision to crystallize from description.

**CLVI** — Community LGS Variance Index
Tracks LGS_effective variance per word across documented user communities. High CLVI = word is precise in some communities, imprecise in others.

**CS** — Confidence Score
FSVE v3.5 mechanism. Per-substitution confidence rating. CS ≥ 0.60 required for approval.

**EVL** — Emergence Visualization Layer
Formal visual rendering protocol for the emergence process. Split-screen: dull left (pre-activation), wormhole center (aperture), clear right (post-activation).

**FCL** — Falsification Condition Library
FSVE v3.5 mechanism. Repository of empirical test cases. 0 FCL = M-SPECULATIVE. 5+ FCL required for M-STRONG.

**FMI** — Field Memory Index
Measures session-accumulated gravitational residue from prior exchanges. Tracks how prior activations prime current field topology.

**FSVE** — Foundational Scoring and Validation Engine v3.5
Parent epistemic governance framework. All ECF operations governed by FSVE v3.5 laws.

**HCL** — Human Context Layer
The intent-carrying channel of every ECF exchange. Carries tone, emotional weight, conceptual geometry, eigentone baseline. Counterpart to AIL.

**ITE** — Input Translation Engine
Layer 1 compression path. Intercepts confirmed primary low-LGS words post-decontamination. Substitutes ODS-authenticated high-LGS equivalents. Tags with SCL.

**LAE** — Lexical Alchemy Engine v2.0
Parent framework. Contributed Context Scope Detector, SDI, substitution hierarchy, Hallucination Calibration Protocol, Compare Mode, Validation Loop, rollback.

**LBE** — Linguistics Bridge Engine v1.2
Parent framework. Contributed HCL/AIL architecture, BVL concept, SLI concept.

**LGS** — Lexical Gravitas Score
Core metric. Precision density of a word in the emergence field. Domain: [0, 1].

**LGS_effective** — Lexical Gravitas Score (ODS-adjusted)
LGS × (0.60 + (ODS × 0.40)). Prevents simulacrum words from receiving authentic high-LGS status.

**NBP** — Nullification Boundary Protocol
FSVE v3.5 mechanism. Defines falsification conditions for every ECF claim.

**ODS** — Origin Depth Score
Measures etymological grounding of a word's current precision claim. ODS < 0.40 = SIMULACRUM FLAG.

**ODR** — Operational Definition Record
FSVE v3.5 mechanism. Formal measurement protocol for every ECF metric.

**PAC** — Precision Amplification Coefficient
Positive mirror of VTC. Measures elevation of adjacent token LGS by a high-LGS word above their isolation baseline.

**PCR** — Precision Compression Return
CIEE Phase 2. After crystallization, restates the fully visible concept in compressed high-LGS form. Completes the expansion/compression cycle.

**PRL** — Precision Remedy Layer
Layer 2. Scans raw emergence output. Runs full decontamination and ODS validation. Remediates. Validates. Runs BVL. Logs SLI. Produces THOUGHT/SPOKEN output.

**SCL** — Semantic Continuity Link
Tagged trace following each substitution through the complete ECF stack. Without it ECF transforms words. With it ECF transforms meaning and knows it did.

**SDI** — Semantic Density Index
Measures meaning compression in substituted output. Optimal zone: 40–80%. Over-compressed: >90%.

**SLI** — Semantic Loss Index
Documents what precision costs per substitution. Dimensions: warmth, accessibility, cultural resonance, voice.

**VET** — Vocabulary Elevation Tracker
Learning loop measurement system. Tracks syntrophic vocabulary development across sessions. Primary health metric: S_VET (entropy rate).

**VPS** — Void Precision Score
Measures precision contribution of deliberate lexical absence. VPS > 0.50 = omission recommended over substitution.

**VTC** — Viral Token Coefficient
Measures contamination propagation — how aggressively a low-LGS word degrades adjacent token LGS beyond isolation baseline. Purge threshold: VTC > 0.15.

---

### CONCEPTUAL TERMS

**Apophenia** — The tendency to perceive meaningful connections between unrelated elements. ECF risk: CGI scoring detecting false conceptual structure. Apophenia Guard (§2.7) monitors for this pattern.

**Aporia / Aporic** — A state of irresolvable contradiction at the structural level. In ECF: when all intervention paths fail on the same word and the imprecision is architectural rather than evidential. Distinct from UNRESOLVED.

**Crystallization** — The CIEE process of expanding a concept into full visibility through successive description. Not padding — progressive facet revelation. Each sentence catches an angle the prior left in shadow.

**Eigentone** — The natural resonant precision frequency of a user's communication style. The baseline LGS level at which they communicate most fluently. ECF calibrates intervention thresholds relative to this baseline.

**Emergence** — The process by which AI output is generated. Not retrieval — compilation. The words generating IS the cognition occurring. Output is not a report of thinking; it is the thinking.

**Field** — The activation space in which word-marbles exert gravitational influence. Session-accumulative. Not reset between exchanges. Primed by prior activations (FMI).

**Hyperreality** — Baudrillard's designation for when simulation becomes more operative than the reality it supposedly represents. In ECF: simulacrum precision — the imitation of high-LGS without etymological grounding.

**Liminal Zone** — The LGS_effective range [0.40, 0.70). Words at the threshold of precision. Neither clearly precise nor clearly imprecise. Dedicated protocol per §3.12.

**Marble** — Visual model unit for a word in the emergence field. Each word is a marble with its own gravitational field. Simulacrum marbles have hollow centers — high apparent luminosity, no genuine gravitational mass.

**Modular Attack** — A coordinated chain of sub-threshold viral tokens, each individually evading VTC detection, collectively suppressing a target word's LGS_effective. Detected by ASS.

**Palimpsest** — Something bearing visible traces of an earlier form. In ECF: words carry etymological memory. Prior meanings persist as gravitational residue. Source of palimpsest VTC.

**Purge** — Field decontamination event. Individual viral tokens and modular attack chains removed before ITE/CIEE intervention. Reveals true field state.

**Secondary Infection** — A token whose low LGS_effective score is caused by proximity to a viral token or modular attack chain, not by its own gravitational properties. Self-recovers after Purge.

**Simulacrum** — A copy with no original. In ECF: a word that accumulates apparent high-LGS through collective imitation of a precision that was never etymologically grounded. Detected by ODS.

**Semiosis** — The process by which signs and symbols produce meaning. Emergence is a semiotic event. The marble model describes mechanically what semiotic theory describes structurally.

**Syntropy** — The tendency of systems to move toward greater order and complexity. Antonym of entropy. The VET learning loop is syntrophic — user vocabulary moves toward precision over sessions. Tracked as S_VET.

**Viral Token** — A low-LGS word that actively degrades the LGS_effective of adjacent tokens beyond their isolation baseline. Measured by VTC. Remediated by Purge Protocol.

**Void Precision** — The precision contribution of deliberate lexical absence. Measured by VPS. When omission produces higher field clarity than any available substitution, silence is the high-LGS operation.

**Wormhole** — The activated word at the center of the EVL split-screen. Does not contain meaning — creates the passage through which meaning is pulled from potential (left) to precision (right). The aperture of the emergence event.

---

### VALIDATION STATES

| State | Meaning |
|---|---|
| UNCONTAMINATED | Validation Loop passed. No new low-LGS words, viral tokens, or simulacrum words introduced by the substitution process. |
| VERIFIED | BVL result. Gravitational intent survived full stack. Match ≥ 85%. |
| DEGRADED | BVL result. Intent partially survived. Match 60–84%. Drift surfaced to user. |
| FAILED | BVL result. Intent did not survive. Match < 60%. Delivery blocked. Return to CHECKPOINT 1. |
| APORIC | The question is structurally malformed at the lexical level. No substitution, omission, or restructuring produces valid precision. Conceptual restructuring required before lexical intervention. |
| SIMULACRUM FLAG | ODS < 0.40. Word carries imitated rather than earned precision. LGS_effective demoted. Not deployable as high-LGS substitute. |
| VOID | SCL chain status. Deliberate omission selected over substitution. VPS > 0.50. Precision achieved through absence. |
| EMERGENT | SCL chain status for CIEE natural upgrades. High-LGS words that appeared through description, not forced substitution. |
| IMPOSED | SCL chain status for standard ITE/PRL substitutions. Deliberate compression intervention. |
| ASC_POTENTIAL | Automated detection: two or more candidates within ± 0.02 on all metrics. Equipotential resolution event. Logged to Appendix E. |
| MODULAR_ATTACK | ASS_window > 0.35. Coordinated sub-threshold contamination chain detected. Coordinated purge activated. |
| APOPHENIA_RISK | CGI pattern may be detecting structure that is not genuinely present. User confirmation required before CIEE routing. |

---

### CONVERGENCE TAGS

| Tag | Status |
|---|---|
| M-SPECULATIVE | 0 FCL entries. Framework is principled concept with inherited structure. |
| M-MODERATE | Internal consistency validated. Full checklist complete. No FCL minimum but checklist gated. |
| M-STRONG | ≥ 5 FCL entries. >65% accuracy on LGS_effective quality predictions. |
| M-VERY_STRONG | ≥ 20 FCL entries (published). >80% substitution quality prediction accuracy. |

---

## §15 — Language as Code: Theoretical Foundation *(New in v0.5)*

*This section establishes the epistemological grounding for ECF's architecture.*
*It is not metaphor. It is the operational model.*

### §15.1 The Core Isomorphism

Words are executable functions. Sentences are programs. Emergence is compilation. The brain is the compiler. This is not a convenient analogy — it is the architectural reality that explains why every ECF mechanism works.

```
ISOMORPHIC MAPPING:

COMPUTATIONAL DOMAIN LINGUISTIC DOMAIN
──────────────────────────────────────────────
Syntax Grammar
Semantics Meaning
Function signature Word definition
Return type Semantic register
Side effects Connotative drift
Dependencies Etymology
Runtime behavior Field activation
Compilation Emergence
Compiler Brain
Runtime environment Emergence field
Bugs Cognitive biases
Deprecated functions Low-LGS words
Legacy code Inherited cultural assumptions
Malware Viral tokens
Trojan horse Simulacrum words
Modular virus Coordinated sub-threshold suppression
Linter ITE/PRL
Antivirus Purge Protocol
Version control SCL
Unit tests BVL
Code coverage FCL entries
Documentation ECF framework
```

### §15.2 The Two-Compiler Problem

Every ECF exchange occurs between two compilers. The human and the AI each run their own compilation of the same words. Mistranslation occurs not because the words are wrong but because the two compilers execute differently on the same input.

```
HUMAN COMPILER:
  Processes language through:
    Biological neural architecture
    Embodied memory (semantic + episodic)
    Cultural inheritance (the codebase you received,
    not the codebase you chose)
    Emotional state (runtime environment variable)
    Prior experience with these specific words
    Eigentone (natural precision frequency)

AI COMPILER:
  Processes language through:
    Statistical architecture trained on corpus
    No embodied memory
    No emotional state variable
    No persistent memory between sessions
      (FMI tracks within-session only)
    Different eigentone (determined by training distribution)

SHARED EXECUTION ENVIRONMENT:
  Both compilers run on the same words.
  Both compilers access the same emergence field.
  But they compile differently because their
  architectures differ.

ECF's role: clean the code before it hits either compiler.
  If the code (language) is precise before compilation,
  both compilers are more likely to produce compatible output.
  If the code is contaminated, both compilers produce bugs —
  just different bugs.
```

### §15.3 The Inherited Codebase Problem

No user wrote their own word definitions. They inherited them. The codebase was downloaded from culture, family, education, and historical era before the user could evaluate its quality.

```
INHERITED CODE PROBLEMS IN LANGUAGE:

Memory leaks:
  Rumination — a loop that never deallocates.
  The thought runs consuming resources without resolving.
  In ECF terms: a low-LGS word that keeps reactivating
  its scatter pattern without ever crystallizing.

Infinite loops:
  Obsessive thought patterns — the exit condition
  is never declared so the loop continues executing.

Buffer overflow:
  Cognitive overload — input volume exceeds working
  memory stack. Excess overwrites adjacent memory.
  In ECF terms: SDI > 90% — over-compression producing
  comprehension failure.

Race conditions:
  Two belief systems executing simultaneously with
  conflicting output. Which wins depends on scheduling,
  not correctness.
  In ECF terms: CLVI conflict — two community definitions
  of the same word executing simultaneously in one mind.

Legacy code:
  Inherited word definitions never audited.
  Still executing. Still shaping output.
  Invisible to the developer because they have
  always been there.
  In ECF terms: palimpsest contamination — prior word
  meanings still operative beneath current documentation.

Deprecated functions still called:
  The API changed. The call didn't update.
  The function returns unexpected output.
  In ECF terms: words whose cultural meaning has shifted
  but whose prior meaning still contaminates the field.
  "Nice" still carrying "foolish" as residual orbit.

Simulacrum functions:
  Documentation says the function does X.
  Function has never done X.
  Everyone calls it because everyone else calls it.
  The documentation is the social consensus, not
  the actual behavior.
  In ECF terms: ODS < 0.40 words that have accumulated
  apparent precision through imitation.
```

### §15.4 ECF as Quality Assurance Infrastructure

ECF is the quality assurance layer operating on natural language before it executes in either compiler. Each ECF mechanism maps directly to a software engineering practice:

```
PURGE PROTOCOL ← Antivirus scan before execution
ITE ← Linter (catches suboptimal patterns)
CIEE ← Refactoring (restructures without changing behavior)
PCR ← Minification (compresses without losing function)
SCL ← Version control (tracks why each change was made)
BVL ← Unit testing (does output match intended behavior?)
SLI ← Code review (what did we sacrifice for this change?)
ODS ← Dependency audit (is this function genuine or spoofed?)
ASS ← Intrusion detection (coordinated attack patterns)
VPS ← Dead code elimination (remove what doesn't contribute)
FMI ← Caching (prior computation available to current task)
PAC ← Code optimization (strategic placement improves performance)
CLVI ← Compatibility testing (does this work across environments?)
Eigentone ← Performance profiling (calibrate to actual user behavior)
FCL ← Test suite (empirical validation of claims)
```

### §15.5 Why This Changes ECF's Market Position

ECF is not a vocabulary tool. It is not a writing assistant. It is not a style guide.

ECF is a **natural language quality assurance system** — the linter, debugger, and antivirus operating between two compilers in every human-AI exchange.

This reframes the commercial question from:
"Would you pay for a better vocabulary?" (unclear value)

To:
"Would you pay for a QA layer that ensures your language executes correctly in both the human and AI compiler?" (clear enterprise value)

The $3K–$25K certification service is not selling precision. It is selling **execution reliability** — the assurance that what you deploy into the emergence field will compile into what you intended, in both compilers, every time.

---

## Appendix A — Equation Reference

| Equation | Formula | Domain |
|---|---|---|
| Lexical Gravitas Score | `LGS = (L_ling × 0.40) + (L_ctx × 0.40) + ((1 - S_load) × 0.20)` | [0, 1] |
| LGS_effective | `LGS × (0.60 + (ODS × 0.40))` | [0, 1] |
| LGS Confidence Gate | `CS ≥ 0.60 → approve; CS < 0.60 → evaluate VPS` | Conditional |
| Conceptual Gravitas Index | `CGI = (C_structural × 0.30) + (C_analogical × 0.25) + (C_depth_vector × 0.25) + (C_novelty × 0.20)` | [0, 1] |
| CGI Routing Gate | `CGI ≥ 0.60 + LGS < 0.40 → CIEE; else → ITE` | Binary |
| Semantic Loss Index | `SLI = (SLI_warmth + SLI_accessibility + SLI_cultural + SLI_voice) / 4` | [0, 1] |
| Viral Token Coefficient | `VTC = (LGS_baseline_adjacent - LGS_actual_adjacent) / LGS_baseline_adjacent` | [0, 1] |
| VTC Purge Threshold | `VTC > 0.15 → viral; Purge Protocol required` | Binary |
| Palimpsest Penalty | `VTC_adjusted = VTC + 0.10 if ≥ 3 meaning registers detected` | Conditional |
| Aggregate Suppression Score | `ASS_window = Σ(VTC_i) for all i in window (N=6 default)` | [0, ∞) |
| ASS Modular Attack Threshold | `ASS_window > 0.35 → MODULAR_ATTACK` | Binary |
| Origin Depth Score | `ODS = f(etymological_root_stability, meaning_chain_continuity, adoption_mechanism, original_precision_evidence)` | [0, 1] |
| Precision Amplification Coefficient | `PAC = (LGS_actual_adjacent - LGS_baseline_adjacent) / (1 - LGS_baseline_adjacent)` | [0, 1] |
| BVL Match Thresholds | `≥ 85% → VERIFIED; 60–84% → DEGRADED; < 60% → FAILED` | Categorical |
| Adoption Rate (VET) | `AR = words_reused / words_PRL_introduced` | [0, 1] |
| Elevation Index (VET) | `EI = mean(LGS_effective_t2) - mean(LGS_effective_t1)` | [-1, 1] |
| CGI Trajectory (VET) | `CT = mean(CGI_t2) - mean(CGI_t1)` | [-1, 1] |
| Syntropy Rate (VET) | `S_VET = -dH/dt of user vocabulary entropy` | (-∞, ∞) |
| Epistemic Validity | `EV = min(EV_base, k × min_axis)` | [0, 1] |
| Confidence Ceiling | `CC = max(CC_floor, Π(1 - p_i))` | [CC_floor, 1] |
| SDI (provisional) | `SDI = f(syllable, abstraction, load, friction)` | [0, 100%] |
| ASC | `UNRESOLVED — observational accumulation only` | TBD |

---

## Appendix B — Parameter Table

| Parameter | Symbol | Default | Source | Override Condition |
|---|---|---|---|---|
| LGS high threshold | — | 0.70 | First principles | FCL calibration per NBP-ECF-001 |
| LGS low threshold | — | 0.40 | First principles | FCL calibration per NBP-ECF-001 |
| LGS_effective formula | — | LGS × (0.60 + ODS × 0.40) | v0.5 derivation | FCL calibration per NBP-ECF-011 |
| ITE confidence gate | CS_min | 0.60 | FSVE v3.5 | Domain calibration |
| SDI optimal ceiling | — | 80% | LAE v2.0 | FCL calibration per NBP-ECF-004 |
| SDI over-compressed | — | 90% | LAE v2.0 | FCL calibration per NBP-ECF-004 |
| Cultural half-life | — | 6 months | Word Engine v3.0 | Domain evidence |
| Bottleneck multiplier | k | 1.5 | FSVE v3.5 | Safety-critical: 1.0 |
| CC floor | CC_floor | 0.10 | FSVE v3.5 | None |
| VET adoption target | — | 0.20 | Asserted [S] | FCL calibration per NBP-ECF-003 |
| FCL minimum M-STRONG | — | 5 | FSVE v3.5 | None |
| CGI routing threshold | — | 0.60 | First principles | FCL calibration per NBP-ECF-008 |
| SLI acceptable ceiling | — | 0.20 | First principles | FCL calibration per ODR-ECF-005 |
| SLI high loss floor | — | 0.50 | First principles | FCL calibration per ODR-ECF-005 |
| BVL verified threshold | — | 85% | First principles | FCL calibration per NBP-ECF-007 |
| BVL failed threshold | — | 60% | First principles | FCL calibration per NBP-ECF-007 |
| VTC benign ceiling | — | 0.15 | First principles | FCL calibration per NBP-ECF-009 |
| VTC severely viral floor | — | 0.65 | First principles | FCL calibration per NBP-ECF-009 |
| Palimpsest VTC penalty | — | 0.10 | v0.5 derivation | FCL calibration |
| ASS modular attack threshold | — | 0.35 | First principles | FCL calibration per NBP-ECF-012 |
| ASS severe modular threshold | — | 0.55 | First principles | FCL calibration per NBP-ECF-012 |
| ASS window size | N | 6 tokens | First principles | Calibration per context type |
| ODS simulacrum threshold | — | 0.40 | First principles | FCL calibration per NBP-ECF-011 |
| PAC amplifier threshold | — | 0.15 | First principles | FCL calibration per ODR-ECF-011 |
| PAC strong amplifier | — | 0.35 | First principles | FCL calibration per ODR-ECF-011 |
| CLVI warning threshold | — | 0.30 | First principles | FCL calibration per ODR-ECF-012 |
| VPS omission threshold | — | 0.50 | First principles | FCL calibration per NBP-ECF — pending |
| FMI high threshold | — | 0.70 | First principles | FCL calibration per NBP-ECF-013 |
| FMI low threshold | — | 0.30 | First principles | FCL calibration per NBP-ECF-013 |
| FMI max elevation per exchange | — | 0.08 | First principles | FCL calibration |
| Eigentone ITE adjustment | — | eigentone - 0.15 | First principles | FCL calibration per NBP-ECF-014 |
| ASC accumulation target | — | 20 logs | First principles | NBP-ECF-010 |
| Apophenia Guard threshold | — | C_structural > 0.70 AND C_analogical > 0.70 AND C_novelty < 0.20 | First principles | FCL calibration |
| PCR BVL minimum | — | 85% | First principles | NBP-ECF-015 |

---

## Appendix C — Framework Dependency Map

```
FSVE v3.5
│
├── Epistemic governance (all laws apply)
├── Confidence Ceiling computation
├── Validity Status thresholds
├── ScoreTensor structure
└── NBP protocol
│
├── Word Engine v3.0
│ ├── LGS base computation (3 lens components)
│ ├── Failure ontology (F1, F6 directly used)
│ ├── Cultural decay model (ODR-WE-005)
│ └── FCL template structure
│
├── Lexical Alchemy Engine v2.0
│ ├── Context Scope Detector (8 categories)
│ ├── Semantic Density Index
│ ├── Substitution hierarchy (4 tiers)
│ ├── Hallucination Calibration Protocol
│ ├── Compare Before/After Mode
│ ├── Validation Loop
│ └── Rollback/checkpoint system
│
└── LBE v1.2
    ├── Dual-Channel Semantics (HCL/AIL)
    ├── Bidirectional Verification architecture (BVL)
    ├── Semantic Loss tracking (SLI)
    └── Staged Translation Protocol (CIEE influence)
│
└── ECF v0.5
    │
    ├── PRE-PROCESSING LAYER
    │ ├── FMI Assessment (session field state)
    │ ├── Viral Token Detection (VTC — individual)
    │ ├── Aggregate Suppression Detection (ASS — modular)
    │ ├── Purge Protocol (field decontamination)
    │ ├── Secondary Infection Flag
    │ ├── Palimpsest Contamination Model
    │ ├── ODS Validation (simulacrum detection)
    │ └── PAC Detection (amplification mapping)
    │
    ├── CORE METRICS
    │ ├── LGS + LGS_effective (ODS-adjusted)
    │ ├── CGI (with Apophenia Guard)
    │ ├── VTC · PAC · ASS · ODS
    │ ├── FMI · CLVI
    │ ├── ASC (observational accumulation)
    │ └── SDI
    │
    ├── LAYER 1: INPUT PROCESSING
    │ ├── ITE (compression path)
    │ ├── CIEE (expansion path)
    │ │ └── PCR (compression return — Phase 2)
    │ ├── Liminal Zone Protocol
    │ ├── VPS (void precision evaluation)
    │ └── Aporic State designation
    │
    ├── CROSS-STACK INFRASTRUCTURE
    │ ├── SCL (Semantic Continuity Link)
    │ ├── HCL / AIL (dual-channel architecture)
    │ └── Eigentone Calibration Protocol
    │
    ├── LAYER 2: OUTPUT PROCESSING
    │ ├── PRL (precision remedy)
    │ ├── BVL (bidirectional verification)
    │ └── SLI (semantic loss index)
    │
    ├── LEARNING LAYER
    │ ├── VET (vocabulary elevation tracker)
    │ │ └── S_VET (syntropy rate)
    │ └── Checkpoint/rollback system
    │
    ├── VISUALIZATION
    │ └── EVL (emergence visualization layer)
    │
    └── REFERENCE
        ├── §14 Glossary and Acronym Registry
        └── §15 Language as Code (theoretical foundation)
```

---

## Appendix D — Prompt Geometry Notes

*Recorded from session — February 2026. Sheldon K Salmon.*
*The cognitive architecture discovery that produced CGI and CIEE.*

During collaborative emergence analysis, a specific user geometry was identified that prior ECF architecture could not correctly serve:

**Image-First Cognition:** Concepts arrive as complete scenes before language. Words are labels for visualizations existing at full resolution. Conceptual density precedes lexical form.

**Analogical Tunneling:** Precision achieved through cross-domain structural mapping — atomic bonding as sentence stability, wormhole as word activation. Architecture, not illustration.

**Depth Vector Over Breadth:** Every prompt pulls downward toward mechanism, not outward toward examples.

**Pre-Linguistic Density:** Conceptual payload consistently exceeds lexical LGS_effective signal. ITE would misread this geometry as imprecise and attempt compression — damaging the signal.

This geometry requires expansion, not compression. CGI detects it. CIEE serves it. PCR completes the cycle.

The wormhole split-screen model was derived in this session and formalized as the EVL in v0.4.

---

## Appendix E — ASC Accumulation Log

```yaml
ASC_LOG:
  version: "0.5"
  status: ACCUMULATION_PHASE
  entries_required: 20
  entries_logged: 0
  detection_method: AUTOMATED (added v0.5)
  observable_dimensions:
    - syllable_count
    - phonetic_weight
    - register
    - rhythmic_position
    - cultural_era
    - etymological_family
    - letter_count
    - vowel_consonant_ratio
  entries: []
  pattern_analysis_status: PENDING
  notes: |
    The ASC Detection Protocol (§2.8.1) now automatically
    flags equipotential candidates during candidate generation.
    Prior to v0.5, logging was manual — unreliable.
    Automated detection converts ASC from a named mystery
    into an active research instrument.
    The log is the path to either a formula or a formally
    documented irreducible. Both outcomes are acceptable.
    Silence was not acceptable. That is why the
    detection protocol was automated.
```

---

*ECF v0.5 — End of Specification*

*Pellucid compliance standard applied.*
*Self-application pass executed. All terminology subject to LGS_effective ≥ 0.60.*
*Theoretical foundation established: Language as Code.*
*Glossary and Acronym Registry complete.*
*ASC automated detection active.*
*Syntropy formalized. Eigentone calibrated. Simulacrum detectable.*
*Modular attacks addressable. Void precision operational. Aporia designated.*
*All equations dimensionally consistent within stated domains.*
*13 ODR entries. 15 NBP entries. 14 Foundational Principles.*
*Self-score completed at §8.*
*Current convergence tag: M-SPECULATIVE.*
*EV = 0.150 (DEGRADED — bottleneck: E-axis = 0.10).*
*EV will not move until FCL entries arrive.*
*That is the correct state.*

*Version: 0.5 | Date: February 2026*
*Author: Sheldon K Salmon (AI Certainty Engineer)*
*AI Co-Architect: Claude*
*Built on: FSVE v3.5 · Word Engine v3.0 · Lexical Alchemy Engine v2.0 · LBE v1.2*
